# packages/server/examples/03_tm_management.py
"""
ç¤ºä¾‹ 3ï¼šç¿»è¯‘è®°å¿†åº“ (TM) ç®¡ç†

æœ¬ç¤ºä¾‹å±•ç¤ºäº†ç¿»è¯‘è®°å¿†åº“çš„æ ¸å¿ƒåŠŸèƒ½ï¼š
1. åˆ›å»ºå’Œç®¡ç†ç¿»è¯‘è®°å¿†åº“
2. æ·»åŠ ç¿»è¯‘å¯¹åˆ°TM
3. æ¨¡ç³ŠåŒ¹é…å’Œç²¾ç¡®åŒ¹é…
4. TMå¤ç”¨å’Œä¼˜åŒ–
5. è´¨é‡è¯„åˆ†å’Œè¿‡æ»¤

é€‚ç”¨äºæé«˜ç¿»è¯‘ä¸€è‡´æ€§å’Œæ•ˆç‡çš„åœºæ™¯ã€‚
"""

import asyncio
from typing import Dict, List, Tuple

import structlog
from _shared import example_runner, print_section_header, print_step, print_success

logger = structlog.get_logger()


# æ¨¡æ‹Ÿå·²æœ‰çš„ç¿»è¯‘è®°å¿†åº“æ•°æ®
EXISTING_TM_DATA = [
    # æŠ€æœ¯æ–‡æ¡£ç¿»è¯‘å¯¹
    (
        "Click the Save button to save your changes.",
        "zh-CN",
        "ç‚¹å‡»ä¿å­˜æŒ‰é’®ä»¥ä¿å­˜æ‚¨çš„æ›´æ”¹ã€‚",
    ),
    ("Please enter a valid email address.", "zh-CN", "è¯·è¾“å…¥æœ‰æ•ˆçš„ç”µå­é‚®ä»¶åœ°å€ã€‚"),
    (
        "Your password must be at least 8 characters long.",
        "zh-CN",
        "æ‚¨çš„å¯†ç å¿…é¡»è‡³å°‘åŒ…å«8ä¸ªå­—ç¬¦ã€‚",
    ),
    ("File uploaded successfully.", "zh-CN", "æ–‡ä»¶ä¸Šä¼ æˆåŠŸã€‚"),
    ("Connection timeout. Please try again.", "zh-CN", "è¿æ¥è¶…æ—¶ã€‚è¯·é‡è¯•ã€‚"),
    # ç”µå•†ç¿»è¯‘å¯¹
    ("Add to Cart", "zh-CN", "æ·»åŠ åˆ°è´­ç‰©è½¦"),
    ("Proceed to Checkout", "zh-CN", "å‰å¾€ç»“è´¦"),
    ("Free shipping on orders over $50", "zh-CN", "è®¢å•æ»¡50ç¾å…ƒå…è´¹é€è´§"),
    ("Customer Reviews", "zh-CN", "å®¢æˆ·è¯„ä»·"),
    ("Product Description", "zh-CN", "äº§å“æè¿°"),
    # æ—¥è¯­ç¿»è¯‘å¯¹
    ("Welcome to our website", "ja-JP", "ç§ãŸã¡ã®ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã¸ã‚ˆã†ã“ã"),
    ("Thank you for your purchase", "ja-JP", "ã”è³¼å…¥ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™"),
    ("Contact Support", "ja-JP", "ã‚µãƒãƒ¼ãƒˆã«é€£çµ¡"),
    # è¥¿ç­ç‰™è¯­ç¿»è¯‘å¯¹
    ("Home Page", "es-ES", "PÃ¡gina de Inicio"),
    ("Search Results", "es-ES", "Resultados de BÃºsqueda"),
    ("User Profile", "es-ES", "Perfil de Usuario"),
]

# æ–°çš„å¾…ç¿»è¯‘å†…å®¹ï¼ˆç”¨äºæµ‹è¯•åŒ¹é…ï¼‰
NEW_CONTENT_TO_TRANSLATE = [
    "Click the Save button to save your work.",  # ä¸ç°æœ‰TMç›¸ä¼¼
    "Please enter a valid phone number.",  # ä¸ç°æœ‰TMç›¸ä¼¼
    "Add to Wishlist",  # ä¸ç°æœ‰TMç›¸ä¼¼
    "This is a completely new sentence.",  # å®Œå…¨æ–°çš„å†…å®¹
    "File download completed successfully.",  # ä¸ç°æœ‰TMç›¸ä¼¼
    "Welcome to our mobile app",  # ä¸ç°æœ‰TMç›¸ä¼¼
]


async def create_tm_database(coordinator, project_id: str) -> str:
    """
    åˆ›å»ºç¿»è¯‘è®°å¿†åº“ã€‚

    Args:
        coordinator: åè°ƒå™¨å®ä¾‹
        project_id: é¡¹ç›®ID

    Returns:
        str: TMæ•°æ®åº“ID
    """
    print_step(1, "åˆ›å»ºç¿»è¯‘è®°å¿†åº“")

    # æ¨¡æ‹Ÿåˆ›å»ºTMæ•°æ®åº“
    tm_id = f"tm_{project_id}_multilang"

    # åœ¨å®é™…å®ç°ä¸­ï¼Œè¿™é‡Œä¼šè°ƒç”¨ï¼š
    # tm_id = await coordinator.create_tm_database(
    #     name=f"{project_id} Multilingual TM",
    #     description="å¤šè¯­è¨€ç¿»è¯‘è®°å¿†åº“",
    #     source_lang="en-US",
    #     target_langs=["zh-CN", "ja-JP", "es-ES"]
    # )

    print_success("ç¿»è¯‘è®°å¿†åº“åˆ›å»ºå®Œæˆ", tm_id=tm_id)
    return tm_id


async def populate_tm_database(coordinator, tm_id: str) -> None:
    """
    å‘TMæ•°æ®åº“æ·»åŠ ç¿»è¯‘å¯¹ã€‚

    Args:
        coordinator: åè°ƒå™¨å®ä¾‹
        tm_id: TMæ•°æ®åº“ID
    """
    print_step(2, f"å‘TMæ•°æ®åº“æ·»åŠ  {len(EXISTING_TM_DATA)} æ¡ç¿»è¯‘å¯¹")

    added_count = 0
    for source_text, target_lang, target_text in EXISTING_TM_DATA:
        # åœ¨å®é™…å®ç°ä¸­ï¼Œè¿™é‡Œä¼šè°ƒç”¨ï¼š
        # await coordinator.add_tm_entry(
        #     tm_id=tm_id,
        #     source_text=source_text,
        #     target_text=target_text,
        #     source_lang="en-US",
        #     target_lang=target_lang,
        #     quality_score=0.95
        # )
        added_count += 1

    print_success("TMæ•°æ®åº“å¡«å……å®Œæˆ", entries_added=added_count)


def calculate_fuzzy_match_score(source: str, target: str) -> float:
    """
    è®¡ç®—æ¨¡ç³ŠåŒ¹é…åˆ†æ•°ï¼ˆç®€åŒ–ç‰ˆï¼‰ã€‚

    Args:
        source: æºæ–‡æœ¬
        target: ç›®æ ‡æ–‡æœ¬

    Returns:
        float: åŒ¹é…åˆ†æ•° (0.0 - 1.0)
    """
    # ç®€åŒ–çš„ç›¸ä¼¼åº¦è®¡ç®—
    source_words = set(source.lower().split())
    target_words = set(target.lower().split())

    if not source_words or not target_words:
        return 0.0

    intersection = source_words.intersection(target_words)
    union = source_words.union(target_words)

    return len(intersection) / len(union)


async def perform_tm_matching(
    coordinator, tm_id: str
) -> Dict[str, List[Tuple[str, float, str]]]:
    """
    å¯¹æ–°å†…å®¹æ‰§è¡ŒTMåŒ¹é…ã€‚

    Args:
        coordinator: åè°ƒå™¨å®ä¾‹
        tm_id: TMæ•°æ®åº“ID

    Returns:
        Dict[str, List[Tuple[str, float, str]]]: åŒ¹é…ç»“æœ
    """
    print_step(3, "æ‰§è¡ŒTMåŒ¹é…åˆ†æ")

    match_results = {}

    for new_text in NEW_CONTENT_TO_TRANSLATE:
        matches = []

        # å¯¹æ¯ä¸ªç°æœ‰TMæ¡ç›®è®¡ç®—åŒ¹é…åˆ†æ•°
        for source_text, target_lang, target_text in EXISTING_TM_DATA:
            if target_lang == "zh-CN":  # åªåŒ¹é…ä¸­æ–‡ç¿»è¯‘
                score = calculate_fuzzy_match_score(new_text, source_text)
                if score > 0.3:  # åªä¿ç•™ç›¸å…³æ€§è¾ƒé«˜çš„åŒ¹é…
                    matches.append((source_text, score, target_text))

        # æŒ‰åŒ¹é…åˆ†æ•°æ’åº
        matches.sort(key=lambda x: x[1], reverse=True)
        match_results[new_text] = matches[:3]  # åªä¿ç•™å‰3ä¸ªåŒ¹é…

    print_success("TMåŒ¹é…å®Œæˆ", processed_texts=len(NEW_CONTENT_TO_TRANSLATE))
    return match_results


async def display_match_results(
    match_results: Dict[str, List[Tuple[str, float, str]]],
) -> None:
    """
    æ˜¾ç¤ºåŒ¹é…ç»“æœã€‚

    Args:
        match_results: åŒ¹é…ç»“æœå­—å…¸
    """
    print_section_header("TMåŒ¹é…ç»“æœåˆ†æ", "ğŸ”")

    for i, (new_text, matches) in enumerate(match_results.items(), 1):
        logger.info("å¾…ç¿»è¯‘æ–‡æœ¬", åºå·=i, æ–‡æœ¬=new_text)

        if not matches:
            logger.warning("æ— åŒ¹é…ç»“æœ - éœ€è¦æ–°ç¿»è¯‘")
            continue

        logger.info("TMåŒ¹é…ç»“æœ")
        for j, (source, score, target) in enumerate(matches, 1):
            match_type = (
                "ğŸŸ¢ ç²¾ç¡®åŒ¹é…"
                if score >= 0.9
                else "ğŸŸ¡ æ¨¡ç³ŠåŒ¹é…"
                if score >= 0.7
                else "ğŸŸ  ä½ç›¸ä¼¼åº¦"
            )
            logger.info(
                "åŒ¹é…é¡¹",
                åºå·=j,
                åŒ¹é…ç±»å‹=match_type,
                ç›¸ä¼¼åº¦=f"{score:.1%}",
                æºæ–‡æœ¬=source,
                å»ºè®®è¯‘æ–‡=target,
            )


async def simulate_tm_optimization(coordinator, tm_id: str) -> None:
    """
    æ¨¡æ‹ŸTMä¼˜åŒ–è¿‡ç¨‹ã€‚

    Args:
        coordinator: åè°ƒå™¨å®ä¾‹
        tm_id: TMæ•°æ®åº“ID
    """
    print_step(4, "æ‰§è¡ŒTMä¼˜åŒ–")

    optimization_stats = {
        "duplicates_removed": 3,
        "low_quality_filtered": 2,
        "entries_merged": 1,
        "final_count": len(EXISTING_TM_DATA) - 6,
    }

    # åœ¨å®é™…å®ç°ä¸­ï¼Œè¿™é‡Œä¼šæ‰§è¡Œï¼š
    # - é‡å¤æ¡ç›®æ£€æµ‹å’Œåˆå¹¶
    # - ä½è´¨é‡ç¿»è¯‘è¿‡æ»¤
    # - ç›¸ä¼¼æ¡ç›®åˆå¹¶
    # - è´¨é‡è¯„åˆ†æ›´æ–°

    print_success("TMä¼˜åŒ–å®Œæˆ", **optimization_stats)


async def generate_tm_statistics(
    match_results: Dict[str, List[Tuple[str, float, str]]],
) -> None:
    """
    ç”ŸæˆTMä½¿ç”¨ç»Ÿè®¡ã€‚

    Args:
        match_results: åŒ¹é…ç»“æœå­—å…¸
    """
    print_section_header("TMä½¿ç”¨ç»Ÿè®¡", "ğŸ“Š")

    total_texts = len(match_results)
    exact_matches = 0
    fuzzy_matches = 0
    no_matches = 0

    for matches in match_results.values():
        if not matches:
            no_matches += 1
        elif matches[0][1] >= 0.9:
            exact_matches += 1
        else:
            fuzzy_matches += 1

    print("ğŸ“ˆ åŒ¹é…ç»Ÿè®¡:")
    print(f"   â€¢ æ€»æ–‡æœ¬æ•°: {total_texts}")
    print(f"   â€¢ ç²¾ç¡®åŒ¹é…: {exact_matches} ({exact_matches / total_texts:.1%})")
    print(f"   â€¢ æ¨¡ç³ŠåŒ¹é…: {fuzzy_matches} ({fuzzy_matches / total_texts:.1%})")
    print(f"   â€¢ æ— åŒ¹é…: {no_matches} ({no_matches / total_texts:.1%})")

    potential_savings = (exact_matches + fuzzy_matches * 0.5) / total_texts
    print(f"\nğŸ’° é¢„ä¼°æ•ˆç‡æå‡: {potential_savings:.1%}")

    print("\nğŸ¯ TMæ•°æ®åº“çŠ¶æ€:")
    print(f"   â€¢ æ€»æ¡ç›®æ•°: {len(EXISTING_TM_DATA)}")
    print("   â€¢ æ”¯æŒè¯­è¨€: zh-CN, ja-JP, es-ES")
    print("   â€¢ å¹³å‡è´¨é‡åˆ†: 95%")


async def demonstrate_tm_workflow(coordinator, project_id: str) -> None:
    """
    æ¼”ç¤ºå®Œæ•´çš„TMå·¥ä½œæµç¨‹ã€‚

    Args:
        coordinator: åè°ƒå™¨å®ä¾‹
        project_id: é¡¹ç›®ID
    """
    print_step(5, "æ¼”ç¤ºTMè¾…åŠ©ç¿»è¯‘å·¥ä½œæµ")

    # æ¨¡æ‹Ÿä½¿ç”¨TMè¿›è¡Œç¿»è¯‘
    workflow_stats = {
        "tm_suggestions_used": 4,
        "manual_translations": 2,
        "time_saved_minutes": 15,
        "consistency_score": 0.92,
    }

    print("\nğŸ”„ TMè¾…åŠ©ç¿»è¯‘æµç¨‹:")
    print("   1. æå–å¾…ç¿»è¯‘æ–‡æœ¬")
    print("   2. æŸ¥è¯¢TMæ•°æ®åº“")
    print("   3. åº”ç”¨é«˜è´¨é‡åŒ¹é…")
    print("   4. äººå·¥å®¡æ ¸å’Œè°ƒæ•´")
    print("   5. æ›´æ–°TMæ•°æ®åº“")

    print_success("TMå·¥ä½œæµæ¼”ç¤ºå®Œæˆ", **workflow_stats)


async def main() -> None:
    """æ‰§è¡ŒTMç®¡ç†ç¤ºä¾‹ã€‚"""
    print_section_header("ç¿»è¯‘è®°å¿†åº“ç®¡ç†æ¼”ç¤º", "ğŸ§ ")

    async with example_runner("tm_management.db") as coordinator:
        project_id = "multilingual-platform"

        # åˆ›å»ºTMæ•°æ®åº“
        tm_id = await create_tm_database(coordinator, project_id)

        # å¡«å……TMæ•°æ®åº“
        await populate_tm_database(coordinator, tm_id)

        # æ‰§è¡ŒTMåŒ¹é…
        match_results = await perform_tm_matching(coordinator, tm_id)

        # æ˜¾ç¤ºåŒ¹é…ç»“æœ
        await display_match_results(match_results)

        # TMä¼˜åŒ–
        await simulate_tm_optimization(coordinator, tm_id)

        # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
        await generate_tm_statistics(match_results)

        # æ¼”ç¤ºå®Œæ•´å·¥ä½œæµ
        await demonstrate_tm_workflow(coordinator, project_id)

        print_section_header("TMç®¡ç†å®Œæˆ", "ğŸ‰")
        print("\nğŸ”— ä¸‹ä¸€æ­¥: è¿è¡Œ 04_collaboration_workflow.py æŸ¥çœ‹åä½œå·¥ä½œæµç¤ºä¾‹")


if __name__ == "__main__":
    asyncio.run(main())
