============================= test session starts ==============================
platform darwin -- Python 3.12.11, pytest-8.4.1, pluggy-1.6.0
rootdir: /Users/saken/Library/CloudStorage/坚果云-saken.w@163.com/工作同步/Code/Trans-Hub/packages/server
configfile: pytest.ini
plugins: asyncio-1.1.0, cov-6.2.1
asyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
collected 7 items

tests/integration/application/test_app_flow.py ......                    [ 85%]
tests/integration/workers/test_worker_run_once.py F                      [100%]

=================================== FAILURES ===================================
________________ test_worker_processes_draft_task_successfully _________________

self = <trans_hub.application.processors.TranslationProcessor object at 0x11bab6390>
uow = <trans_hub.infrastructure.uow.SqlAlchemyUnitOfWork object at 0x11bab6ff0>
item = ContentItem(head_id='34b4168c-1fc4-486b-8ddb-d228e8fdcb0a', current_rev_id='8b38bd4a-6baf-462c-9624-8011a435d24d', cur...test.namespace.v1', source_payload={'text': 'Source text c5a893'}, source_lang='en', target_lang='de', variant_key='-')
output = EngineSuccess(translated_text="Translated('Source text c5a893') to fr", from_cache=False)
active_engine = <tests.helpers.tools.fakes.FakeTranslationEngine object at 0x11bab76b0>

    async def _handle_success(
        self,
        uow: "IUnitOfWork",
        item: ContentItem,
        output: EngineSuccess,
        active_engine: "BaseTranslationEngine",
    ) -> None:
        """在给定的 UoW 中处理单个翻译成功的结果。"""
        try:
            translated_payload = dict(item.source_payload)
            translated_payload[self.PAYLOAD_TEXT_KEY] = output.translated_text
    
>           new_rev_id = await uow.translations.create_revision(
                head_id=item.head_id,
                project_id=item.project_id,
                content_id=item.content_id,
                target_lang=item.target_lang,
                variant_key=item.variant_key,
                status=TranslationStatus.REVIEWED,
                revision_no=item.current_no + 1,
                translated_payload_json=translated_payload,
                engine_name=active_engine.name(),
                engine_version=active_engine.VERSION,
            )

src/trans_hub/application/processors.py:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <trans_hub.infrastructure.persistence.repositories._translation_repo.SqlAlchemyTranslationRepository object at 0x11bab5cd0>
data = {'content_id': '110199d4-1732-4b66-826e-cf7dbbe68391', 'engine_name': 'faketranslation', 'engine_version': '0.1.0-fake', 'project_id': 'test-project', ...}
head_id = '34b4168c-1fc4-486b-8ddb-d228e8fdcb0a'
head_stmt = <sqlalchemy.sql.selectable.Select object at 0x11bae1b80>
head = <[DetachedInstanceError('Instance <ThTransHead at 0x11bae06e0> is not bound to a Session; attribute refresh operation cannot proceed') raised in repr()] ThTransHead object at 0x11bae06e0>
content = <[DetachedInstanceError('Instance <ThContent at 0x11bae1be0> is not bound to a Session; attribute refresh operation cannot proceed') raised in repr()] ThContent object at 0x11bae1be0>
variant_key = '-'
new_rev = ThTransRev(project_id='test-project', content_id='110199d4-1732-4b66-826e-cf7dbbe68391', target_lang='de', revision_no...ad_json={'text': "Translated('Source text c5a893') to fr"}, engine_name='faketranslation', engine_version='0.1.0-fake')

    async def create_revision(self, **data: Any) -> str:
        """
        创建一条新的修订，并更新其所属头指针的状态。
        """
        head_id = data.pop("head_id")
    
        # ThTransHead 的主键是复合键
        head_stmt = select(ThTransHead).where(
            ThTransHead.project_id == data["project_id"], ThTransHead.id == head_id
        )
        head = (await self._session.execute(head_stmt)).scalar_one_or_none()
    
        if not head:
            raise NoResultFound(
                f"翻译头记录未找到: project_id={data['project_id']}, head_id={head_id}"
            )
    
        content = await self._session.get(ThContent, data["content_id"])
        if not content:
            raise NoResultFound(f"内容记录未找到: content_id={data['content_id']}")
    
        # 从data中提取variant_key，因为该字段设置了init=False
        variant_key = data.pop("variant_key", "-")
    
        new_rev = ThTransRev(
            id=str(uuid.uuid4()), src_payload_json=content.source_payload_json, **data
        )
        new_rev.variant_key = variant_key
        self._session.add(new_rev)
>       await self._session.flush()  # 确保 new_rev.id 可用
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^

src/trans_hub/infrastructure/persistence/repositories/_translation_repo.py:157: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.ext.asyncio.session.AsyncSession object at 0x11bab5eb0>
objects = None

    async def flush(self, objects: Optional[Sequence[Any]] = None) -> None:
        """Flush all the object changes to the database.
    
        .. seealso::
    
            :meth:`_orm.Session.flush` - main documentation for flush
    
        """
>       await greenlet_spawn(self.sync_session.flush, objects=objects)

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/sqlalchemy/ext/asyncio/session.py:801: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <bound method Session.flush of <sqlalchemy.orm.session.Session object at 0x11bab6750>>
_require_await = False, args = (), kwargs = {'objects': None}
context = <_AsyncIoGreenlet object at 0x11bae86c0 (otid=0x111abff60) dead>
switch_occurred = False

    async def greenlet_spawn(
        fn: Callable[..., _T],
        *args: Any,
        _require_await: bool = False,
        **kwargs: Any,
    ) -> _T:
        """Runs a sync function ``fn`` in a new greenlet.
    
        The sync function can then use :func:`await_only` to wait for async
        functions.
    
        :param fn: The sync callable to call.
        :param \\*args: Positional arguments to pass to the ``fn`` callable.
        :param \\*\\*kwargs: Keyword arguments to pass to the ``fn`` callable.
        """
    
        result: Any
        context = _AsyncIoGreenlet(fn, getcurrent())
        # runs the function synchronously in gl greenlet. If the execution
        # is interrupted by await_only, context is not dead and result is a
        # coroutine to wait. If the context is dead the function has
        # returned, and its result can be returned.
        switch_occurred = False
>       result = context.switch(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/sqlalchemy/util/_concurrency_py3k.py:190: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x11bab6750>, objects = None

    def flush(self, objects: Optional[Sequence[Any]] = None) -> None:
        """Flush all the object changes to the database.
    
        Writes out all pending object creations, deletions and modifications
        to the database as INSERTs, DELETEs, UPDATEs, etc.  Operations are
        automatically ordered by the Session's unit of work dependency
        solver.
    
        Database operations will be issued in the current transactional
        context and do not affect the state of the transaction, unless an
        error occurs, in which case the entire transaction is rolled back.
        You may flush() as often as you like within a transaction to move
        changes from Python to the database's transaction buffer.
    
        :param objects: Optional; restricts the flush operation to operate
          only on elements that are in the given collection.
    
          This feature is for an extremely narrow set of use cases where
          particular objects may need to be operated upon before the
          full flush() occurs.  It is not intended for general use.
    
        """
    
        if self._flushing:
>           raise sa_exc.InvalidRequestError("Session is already flushing")
E           sqlalchemy.exc.InvalidRequestError: Session is already flushing

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/sqlalchemy/orm/session.py:4339: InvalidRequestError

During handling of the above exception, another exception occurred:

uow_factory = <dependency_injector.providers.Factory(<class 'trans_hub.infrastructure.uow.SqlAlchemyUnitOfWork'>) at 0x11540d900>
processor = <trans_hub.application.processors.TranslationProcessor object at 0x11bab6390>
active_engine = <tests.helpers.tools.fakes.FakeTranslationEngine object at 0x11bab76b0>
batch_size = 10

    async def run_once(
        uow_factory: UowFactory,
        processor: TranslationProcessor,
        active_engine: BaseTranslationEngine[Any],
        batch_size: int,
    ) -> None:
        """
        执行一轮 Worker 的核心处理逻辑。
        它现在使用 UoW 来确保拉取和处理任务的原子性。
        """
        tasks_processed = 0
        try:
            # Worker 的核心逻辑现在在一个独立的 UoW 中运行
            async with uow_factory() as uow:
                # 使用流式处理，但在同一个 session 中
                # 注意：这里的 stream_drafts 内部使用了 FOR UPDATE SKIP LOCKED
                # 它将在事务提交前一直持有行锁
                async for batch in uow.translations.stream_drafts(batch_size):
                    if not batch:
                        continue
    
                    logger.info("获取到新一批翻译任务，正在处理...", count=len(batch))
    
                    # 处理器现在也接收 UoW 实例，以便在同一个事务中执行更新
>                   await processor.process_batch(uow, batch, active_engine)

src/trans_hub/workers/_translation_worker.py:45: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <trans_hub.application.processors.TranslationProcessor object at 0x11bab6390>
uow = <trans_hub.infrastructure.uow.SqlAlchemyUnitOfWork object at 0x11bab6ff0>
batch = [ContentItem(head_id='14e75290-78e7-4c9d-8f93-cffca1f7758b', current_rev_id='62837c67-8a0b-43a0-99a7-5fba1653c5f4', cu...est.namespace.v1', source_payload={'text': 'Source text c5a893'}, source_lang='en', target_lang='de', variant_key='-')]
active_engine = <tests.helpers.tools.fakes.FakeTranslationEngine object at 0x11bab76b0>

    async def process_batch(
        self,
        uow: "IUnitOfWork",
        batch: list[ContentItem],
        active_engine: "BaseTranslationEngine",
    ) -> None:
        """
        在给定的 UoW 中处理一批待翻译的内容条目。
        """
        if not batch:
            return
    
        texts = [item.source_payload.get(self.PAYLOAD_TEXT_KEY, "") for item in batch]
        item_template = batch[0]
        engine_outputs = await active_engine.atranslate_batch(
            texts=texts,
            target_lang=item_template.target_lang,
            source_lang=item_template.source_lang,
        )
    
        success_tasks = []
        for item, output in zip(batch, engine_outputs):
            if isinstance(output, EngineSuccess):
                success_tasks.append(
                    self._handle_success(uow, item, output, active_engine)
                )
            elif isinstance(output, EngineError):
                logger.error(
                    "引擎翻译失败，将等待重试",
                    head_id=item.head_id,
                    error=output.error_message,
                    is_retryable=output.is_retryable,
                )
    
        if success_tasks:
>           await asyncio.gather(*success_tasks)

src/trans_hub/application/processors.py:77: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = None
future = <_GatheringFuture finished exception=MissingGreenlet("greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place?")>

    def __wakeup(self, future):
        try:
>           future.result()

/Users/saken/.pyenv/versions/3.12.11/lib/python3.12/asyncio/tasks.py:385: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = None

    def __step_run_and_handle_result(self, exc):
        coro = self._coro
        try:
            if exc is None:
                # We use the `send` method directly, because coroutines
                # don't have `__iter__` and `__next__` methods.
>               result = coro.send(None)
                         ^^^^^^^^^^^^^^^

/Users/saken/.pyenv/versions/3.12.11/lib/python3.12/asyncio/tasks.py:314: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <trans_hub.application.processors.TranslationProcessor object at 0x11bab6390>
uow = <trans_hub.infrastructure.uow.SqlAlchemyUnitOfWork object at 0x11bab6ff0>
item = ContentItem(head_id='34b4168c-1fc4-486b-8ddb-d228e8fdcb0a', current_rev_id='8b38bd4a-6baf-462c-9624-8011a435d24d', cur...test.namespace.v1', source_payload={'text': 'Source text c5a893'}, source_lang='en', target_lang='de', variant_key='-')
output = EngineSuccess(translated_text="Translated('Source text c5a893') to fr", from_cache=False)
active_engine = <tests.helpers.tools.fakes.FakeTranslationEngine object at 0x11bab76b0>

    async def _handle_success(
        self,
        uow: "IUnitOfWork",
        item: ContentItem,
        output: EngineSuccess,
        active_engine: "BaseTranslationEngine",
    ) -> None:
        """在给定的 UoW 中处理单个翻译成功的结果。"""
        try:
            translated_payload = dict(item.source_payload)
            translated_payload[self.PAYLOAD_TEXT_KEY] = output.translated_text
    
            new_rev_id = await uow.translations.create_revision(
                head_id=item.head_id,
                project_id=item.project_id,
                content_id=item.content_id,
                target_lang=item.target_lang,
                variant_key=item.variant_key,
                status=TranslationStatus.REVIEWED,
                revision_no=item.current_no + 1,
                translated_payload_json=translated_payload,
                engine_name=active_engine.name(),
                engine_version=active_engine.VERSION,
            )
    
            source_text_for_tm = item.source_payload.get(self.PAYLOAD_TEXT_KEY, "")
            source_fields = {
                "text": tm_domain.normalize_text_for_tm(source_text_for_tm)
            }
            reuse_sha = tm_domain.build_reuse_key(
                namespace=item.namespace, reduced_keys={}, source_fields=source_fields
            )
    
            tm_id = await uow.tm.upsert_entry(
                project_id=item.project_id,
                namespace=item.namespace,
                src_hash=reuse_sha,
                src_lang=item.source_lang or "auto",
                tgt_lang=item.target_lang,
                variant_key=item.variant_key,
                src_payload=source_fields,
                tgt_payload=translated_payload,
                approved=True,
            )
            await uow.tm.link_revision_to_tm(new_rev_id, tm_id, item.project_id)
    
        except Exception:
>           logger.error(
                "保存成功翻译结果到数据库时失败", head_id=item.head_id, exc_info=True
            )

src/trans_hub/application/processors.py:126: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <BoundLoggerFilteringAtNotset(context={}, processors=[<function merge_contextvars at 0x1134ea340>, <function add_log_l...e0>, <structlog.processors.TimeStamper object at 0x113cf3980>, <structlog.dev.ConsoleRenderer object at 0x114007a70>])>
event = '保存成功翻译结果到数据库时失败', args = ()
kw = {'exc_info': True, 'head_id': '34b4168c-1fc4-486b-8ddb-d228e8fdcb0a'}

    def meth(self: Any, event: str, *args: Any, **kw: Any) -> Any:
        if not args:
>           return self._proxy_to_logger(name, event, **kw)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/structlog/_native.py:134: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <BoundLoggerFilteringAtNotset(context={}, processors=[<function merge_contextvars at 0x1134ea340>, <function add_log_l...e0>, <structlog.processors.TimeStamper object at 0x113cf3980>, <structlog.dev.ConsoleRenderer object at 0x114007a70>])>
method_name = 'error', event = '保存成功翻译结果到数据库时失败'
event_kw = {'exc_info': True, 'head_id': '34b4168c-1fc4-486b-8ddb-d228e8fdcb0a'}

    def _proxy_to_logger(
        self, method_name: str, event: str | None = None, **event_kw: Any
    ) -> Any:
        """
        Run processor chain on event & call *method_name* on wrapped logger.
    
        DRY convenience method that runs :func:`_process_event`, takes care of
        handling :exc:`structlog.DropEvent`, and finally calls *method_name* on
        :attr:`_logger` with the result.
    
        Args:
            method_name:
                The name of the method that's going to get called.  Technically
                it should be identical to the method the user called because it
                also get passed into processors.
    
            event:
                The event -- usually the first positional argument to a logger.
    
            event_kw:
                Additional event keywords.  For example if someone calls
                ``log.info("foo", bar=42)``, *event* would to be ``"foo"`` and
                *event_kw* ``{"bar": 42}``.
    
        .. note::
            Despite underscore available to custom wrapper classes.
    
            See also `custom-wrappers`.
        """
        try:
>           args, kw = self._process_event(method_name, event, event_kw)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/structlog/_base.py:214: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <BoundLoggerFilteringAtNotset(context={}, processors=[<function merge_contextvars at 0x1134ea340>, <function add_log_l...e0>, <structlog.processors.TimeStamper object at 0x113cf3980>, <structlog.dev.ConsoleRenderer object at 0x114007a70>])>
method_name = 'error', event = '保存成功翻译结果到数据库时失败'
event_kw = {'exc_info': True, 'head_id': '34b4168c-1fc4-486b-8ddb-d228e8fdcb0a'}

    def _process_event(
        self, method_name: str, event: str | None, event_kw: dict[str, Any]
    ) -> tuple[Sequence[Any], Mapping[str, Any]]:
        """
        Combines creates an ``event_dict`` and runs the chain.
    
        Call it to combine your *event* and *context* into an event_dict and
        process using the processor chain.
    
        Args:
            method_name:
                The name of the logger method.  Is passed into the processors.
    
            event:
                The event -- usually the first positional argument to a logger.
    
            event_kw:
                Additional event keywords.  For example if someone calls
                ``log.info("foo", bar=42)``, *event* would to be ``"foo"`` and
                *event_kw* ``{"bar": 42}``.
    
        Raises:
            structlog.DropEvent: if log entry should be dropped.
    
            ValueError:
                if the final processor doesn't return a str, bytes, bytearray,
                tuple, or a dict.
    
        Returns:
             `tuple` of ``(*args, **kw)``
    
        .. note::
            Despite underscore available to custom wrapper classes.
    
            See also `custom-wrappers`.
    
        .. versionchanged:: 14.0.0
            Allow final processor to return a `dict`.
        .. versionchanged:: 20.2.0
            Allow final processor to return `bytes`.
        .. versionchanged:: 21.2.0
            Allow final processor to return a `bytearray`.
        """
        # We're typing it as Any, because processors can return more than an
        # EventDict.
        event_dict: Any = self._context.copy()
        event_dict.update(**event_kw)
    
        if event is not None:
            event_dict["event"] = event
        for proc in self._processors:
>           event_dict = proc(self._logger, method_name, event_dict)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/structlog/_base.py:165: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <structlog.dev.ConsoleRenderer object at 0x114007a70>
logger = <PrintLogger(file=<_io.TextIOWrapper name="<_io.FileIO name=6 mode='rb+' closefd=True>" mode='r+' encoding='utf-8'>)>
name = 'error', event_dict = {'head_id': '34b4168c-1fc4-486b-8ddb-d228e8fdcb0a'}

    def __call__(
        self, logger: WrappedLogger, name: str, event_dict: EventDict
    ) -> str:
        stack = event_dict.pop("stack", None)
        exc = event_dict.pop("exception", None)
        exc_info = event_dict.pop("exc_info", None)
    
        kvs = [
            col.formatter(col.key, val)
            for col in self._columns
            if (val := event_dict.pop(col.key, _NOTHING)) is not _NOTHING
        ] + [
            self._default_column_formatter(key, event_dict[key])
            for key in (sorted(event_dict) if self._sort_keys else event_dict)
        ]
    
        sio = StringIO()
        sio.write((" ".join(kv for kv in kvs if kv)).rstrip(" "))
    
        if stack is not None:
            sio.write("\n" + stack)
            if exc_info or exc is not None:
                sio.write("\n\n" + "=" * 79 + "\n")
    
        if exc_info:
            exc_info = _figure_out_exc_info(exc_info)
    
            if exc_info != (None, None, None):
>               self._exception_formatter(sio, exc_info)

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/structlog/dev.py:738: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = RichTracebackFormatter(color_system='truecolor', show_locals=True, max_frames=100, theme=None, word_wrap=False, extra_...uides=True, locals_max_length=10, locals_max_string=80, locals_hide_dunder=True, locals_hide_sunder=False, suppress=())
sio = <_io.StringIO object at 0x11b9a96c0>
exc_info = (<class 'sqlalchemy.exc.InvalidRequestError'>, InvalidRequestError('Session is already flushing'), <traceback object at 0x11bae8ac0>)

    def __call__(self, sio: TextIO, exc_info: ExcInfo) -> None:
        if self.width == -1:
            self.width, _ = shutil.get_terminal_size((80, 0))
    
        sio.write("\n")
    
        Console(
            file=sio, color_system=self.color_system, width=self.width
        ).print(
>           Traceback.from_exception(
                *exc_info,
                show_locals=self.show_locals,
                max_frames=self.max_frames,
                theme=self.theme,
                word_wrap=self.word_wrap,
                extra_lines=self.extra_lines,
                width=self.width,
                indent_guides=self.indent_guides,
                locals_max_length=self.locals_max_length,
                locals_max_string=self.locals_max_string,
                locals_hide_dunder=self.locals_hide_dunder,
                locals_hide_sunder=self.locals_hide_sunder,
                suppress=self.suppress,
            )
        )

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/structlog/dev.py:382: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'rich.traceback.Traceback'>
exc_type = <class 'sqlalchemy.exc.InvalidRequestError'>
exc_value = InvalidRequestError('Session is already flushing')
traceback = <traceback object at 0x11bae8ac0>

    @classmethod
    def from_exception(
        cls,
        exc_type: Type[Any],
        exc_value: BaseException,
        traceback: Optional[TracebackType],
        *,
        width: Optional[int] = 100,
        code_width: Optional[int] = 88,
        extra_lines: int = 3,
        theme: Optional[str] = None,
        word_wrap: bool = False,
        show_locals: bool = False,
        locals_max_length: int = LOCALS_MAX_LENGTH,
        locals_max_string: int = LOCALS_MAX_STRING,
        locals_hide_dunder: bool = True,
        locals_hide_sunder: bool = False,
        indent_guides: bool = True,
        suppress: Iterable[Union[str, ModuleType]] = (),
        max_frames: int = 100,
    ) -> "Traceback":
        """Create a traceback from exception info
    
        Args:
            exc_type (Type[BaseException]): Exception type.
            exc_value (BaseException): Exception value.
            traceback (TracebackType): Python Traceback object.
            width (Optional[int], optional): Number of characters used to traceback. Defaults to 100.
            code_width (Optional[int], optional): Number of code characters used to traceback. Defaults to 88.
            extra_lines (int, optional): Additional lines of code to render. Defaults to 3.
            theme (str, optional): Override pygments theme used in traceback.
            word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.
            show_locals (bool, optional): Enable display of local variables. Defaults to False.
            indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.
            locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
                Defaults to 10.
            locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.
            locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.
            locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.
            suppress (Iterable[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.
            max_frames (int): Maximum number of frames to show in a traceback, 0 for no maximum. Defaults to 100.
    
        Returns:
            Traceback: A Traceback instance that may be printed.
        """
>       rich_traceback = cls.extract(
            exc_type,
            exc_value,
            traceback,
            show_locals=show_locals,
            locals_max_length=locals_max_length,
            locals_max_string=locals_max_string,
            locals_hide_dunder=locals_hide_dunder,
            locals_hide_sunder=locals_hide_sunder,
        )

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/rich/traceback.py:384: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'rich.traceback.Traceback'>
exc_type = <class 'sqlalchemy.exc.InvalidRequestError'>
exc_value = InvalidRequestError('Session is already flushing')
traceback = <traceback object at 0x11bae8ac0>

    @classmethod
    def extract(
        cls,
        exc_type: Type[BaseException],
        exc_value: BaseException,
        traceback: Optional[TracebackType],
        *,
        show_locals: bool = False,
        locals_max_length: int = LOCALS_MAX_LENGTH,
        locals_max_string: int = LOCALS_MAX_STRING,
        locals_hide_dunder: bool = True,
        locals_hide_sunder: bool = False,
        _visited_exceptions: Optional[Set[BaseException]] = None,
    ) -> Trace:
        """Extract traceback information.
    
        Args:
            exc_type (Type[BaseException]): Exception type.
            exc_value (BaseException): Exception value.
            traceback (TracebackType): Python Traceback object.
            show_locals (bool, optional): Enable display of local variables. Defaults to False.
            locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
                Defaults to 10.
            locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.
            locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.
            locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.
    
        Returns:
            Trace: A Trace instance which you can use to construct a `Traceback`.
        """
    
        stacks: List[Stack] = []
        is_cause = False
    
        from rich import _IMPORT_CWD
    
        notes: List[str] = getattr(exc_value, "__notes__", None) or []
    
        grouped_exceptions: Set[BaseException] = (
            set() if _visited_exceptions is None else _visited_exceptions
        )
    
        def safe_str(_object: Any) -> str:
            """Don't allow exceptions from __str__ to propagate."""
            try:
                return str(_object)
            except Exception:
                return "<exception str() failed>"
    
        while True:
            stack = Stack(
                exc_type=safe_str(exc_type.__name__),
                exc_value=safe_str(exc_value),
                is_cause=is_cause,
                notes=notes,
            )
    
            if sys.version_info >= (3, 11):
                if isinstance(exc_value, (BaseExceptionGroup, ExceptionGroup)):
                    stack.is_group = True
                    for exception in exc_value.exceptions:
                        if exception in grouped_exceptions:
                            continue
                        grouped_exceptions.add(exception)
                        stack.exceptions.append(
                            Traceback.extract(
                                type(exception),
                                exception,
                                exception.__traceback__,
                                show_locals=show_locals,
                                locals_max_length=locals_max_length,
                                locals_hide_dunder=locals_hide_dunder,
                                locals_hide_sunder=locals_hide_sunder,
                                _visited_exceptions=grouped_exceptions,
                            )
                        )
    
            if isinstance(exc_value, SyntaxError):
                stack.syntax_error = _SyntaxError(
                    offset=exc_value.offset or 0,
                    filename=exc_value.filename or "?",
                    lineno=exc_value.lineno or 0,
                    line=exc_value.text or "",
                    msg=exc_value.msg,
                    notes=notes,
                )
    
            stacks.append(stack)
            append = stack.frames.append
    
            def get_locals(
                iter_locals: Iterable[Tuple[str, object]],
            ) -> Iterable[Tuple[str, object]]:
                """Extract locals from an iterator of key pairs."""
                if not (locals_hide_dunder or locals_hide_sunder):
                    yield from iter_locals
                    return
                for key, value in iter_locals:
                    if locals_hide_dunder and key.startswith("__"):
                        continue
                    if locals_hide_sunder and key.startswith("_"):
                        continue
                    yield key, value
    
            for frame_summary, line_no in walk_tb(traceback):
                filename = frame_summary.f_code.co_filename
    
                last_instruction: Optional[Tuple[Tuple[int, int], Tuple[int, int]]]
                last_instruction = None
                if sys.version_info >= (3, 11):
                    instruction_index = frame_summary.f_lasti // 2
                    instruction_position = next(
                        islice(
                            frame_summary.f_code.co_positions(),
                            instruction_index,
                            instruction_index + 1,
                        )
                    )
                    (
                        start_line,
                        end_line,
                        start_column,
                        end_column,
                    ) = instruction_position
                    if (
                        start_line is not None
                        and end_line is not None
                        and start_column is not None
                        and end_column is not None
                    ):
                        last_instruction = (
                            (start_line, start_column),
                            (end_line, end_column),
                        )
    
                if filename and not filename.startswith("<"):
                    if not os.path.isabs(filename):
                        filename = os.path.join(_IMPORT_CWD, filename)
                if frame_summary.f_locals.get("_rich_traceback_omit", False):
                    continue
    
                frame = Frame(
                    filename=filename or "?",
                    lineno=line_no,
                    name=frame_summary.f_code.co_name,
                    locals=(
                        {
>                           key: pretty.traverse(
                                value,
                                max_length=locals_max_length,
                                max_string=locals_max_string,
                            )
                            for key, value in get_locals(frame_summary.f_locals.items())
                            if not (inspect.isfunction(value) or inspect.isclass(value))
                        }
                        if show_locals
                        else None
                    ),
                    last_instruction=last_instruction,
                )

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/rich/traceback.py:559: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

_object = <[DetachedInstanceError('Instance <ThTransHead at 0x11bae06e0> is not bound to a Session; attribute refresh operation cannot proceed') raised in repr()] ThTransHead object at 0x11bae06e0>
max_length = 10, max_string = 80, max_depth = None

    def traverse(
        _object: Any,
        max_length: Optional[int] = None,
        max_string: Optional[int] = None,
        max_depth: Optional[int] = None,
    ) -> Node:
        """Traverse object and generate a tree.
    
        Args:
            _object (Any): Object to be traversed.
            max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
                Defaults to None.
            max_string (int, optional): Maximum length of string before truncating, or None to disable truncating.
                Defaults to None.
            max_depth (int, optional): Maximum depth of data structures, or None for no maximum.
                Defaults to None.
    
        Returns:
            Node: The root of a tree structure which can be used to render a pretty repr.
        """
    
        def to_repr(obj: Any) -> str:
            """Get repr string for an object, but catch errors."""
            if (
                max_string is not None
                and _safe_isinstance(obj, (bytes, str))
                and len(obj) > max_string
            ):
                truncated = len(obj) - max_string
                obj_repr = f"{obj[:max_string]!r}+{truncated}"
            else:
                try:
                    obj_repr = repr(obj)
                except Exception as error:
                    obj_repr = f"<repr-error {str(error)!r}>"
            return obj_repr
    
        visited_ids: Set[int] = set()
        push_visited = visited_ids.add
        pop_visited = visited_ids.remove
    
        def _traverse(obj: Any, root: bool = False, depth: int = 0) -> Node:
            """Walk the object depth first."""
    
            obj_id = id(obj)
            if obj_id in visited_ids:
                # Recursion detected
                return Node(value_repr="...")
    
            obj_type = type(obj)
            children: List[Node]
            reached_max_depth = max_depth is not None and depth >= max_depth
    
            def iter_rich_args(rich_args: Any) -> Iterable[Union[Any, Tuple[str, Any]]]:
                for arg in rich_args:
                    if _safe_isinstance(arg, tuple):
                        if len(arg) == 3:
                            key, child, default = arg
                            if default == child:
                                continue
                            yield key, child
                        elif len(arg) == 2:
                            key, child = arg
                            yield key, child
                        elif len(arg) == 1:
                            yield arg[0]
                    else:
                        yield arg
    
            try:
                fake_attributes = hasattr(
                    obj, "awehoi234_wdfjwljet234_234wdfoijsdfmmnxpi492"
                )
            except Exception:
                fake_attributes = False
    
            rich_repr_result: Optional[RichReprResult] = None
            if not fake_attributes:
                try:
                    if hasattr(obj, "__rich_repr__") and not isclass(obj):
                        rich_repr_result = obj.__rich_repr__()
                except Exception:
                    pass
    
            if rich_repr_result is not None:
                push_visited(obj_id)
                angular = getattr(obj.__rich_repr__, "angular", False)
                args = list(iter_rich_args(rich_repr_result))
                class_name = obj.__class__.__name__
    
                if args:
                    children = []
                    append = children.append
    
                    if reached_max_depth:
                        if angular:
                            node = Node(value_repr=f"<{class_name}...>")
                        else:
                            node = Node(value_repr=f"{class_name}(...)")
                    else:
                        if angular:
                            node = Node(
                                open_brace=f"<{class_name} ",
                                close_brace=">",
                                children=children,
                                last=root,
                                separator=" ",
                            )
                        else:
                            node = Node(
                                open_brace=f"{class_name}(",
                                close_brace=")",
                                children=children,
                                last=root,
                            )
                        for last, arg in loop_last(args):
                            if _safe_isinstance(arg, tuple):
                                key, child = arg
                                child_node = _traverse(child, depth=depth + 1)
                                child_node.last = last
                                child_node.key_repr = key
                                child_node.key_separator = "="
                                append(child_node)
                            else:
                                child_node = _traverse(arg, depth=depth + 1)
                                child_node.last = last
                                append(child_node)
                else:
                    node = Node(
                        value_repr=f"<{class_name}>" if angular else f"{class_name}()",
                        children=[],
                        last=root,
                    )
                pop_visited(obj_id)
            elif _is_attr_object(obj) and not fake_attributes:
                push_visited(obj_id)
                children = []
                append = children.append
    
                attr_fields = _get_attr_fields(obj)
                if attr_fields:
                    if reached_max_depth:
                        node = Node(value_repr=f"{obj.__class__.__name__}(...)")
                    else:
                        node = Node(
                            open_brace=f"{obj.__class__.__name__}(",
                            close_brace=")",
                            children=children,
                            last=root,
                        )
    
                        def iter_attrs() -> (
                            Iterable[Tuple[str, Any, Optional[Callable[[Any], str]]]]
                        ):
                            """Iterate over attr fields and values."""
                            for attr in attr_fields:
                                if attr.repr:
                                    try:
                                        value = getattr(obj, attr.name)
                                    except Exception as error:
                                        # Can happen, albeit rarely
                                        yield (attr.name, error, None)
                                    else:
                                        yield (
                                            attr.name,
                                            value,
                                            attr.repr if callable(attr.repr) else None,
                                        )
    
                        for last, (name, value, repr_callable) in loop_last(iter_attrs()):
                            if repr_callable:
                                child_node = Node(value_repr=str(repr_callable(value)))
                            else:
                                child_node = _traverse(value, depth=depth + 1)
                            child_node.last = last
                            child_node.key_repr = name
                            child_node.key_separator = "="
                            append(child_node)
                else:
                    node = Node(
                        value_repr=f"{obj.__class__.__name__}()", children=[], last=root
                    )
                pop_visited(obj_id)
            elif (
                is_dataclass(obj)
                and not _safe_isinstance(obj, type)
                and not fake_attributes
                and _is_dataclass_repr(obj)
            ):
                push_visited(obj_id)
                children = []
                append = children.append
                if reached_max_depth:
                    node = Node(value_repr=f"{obj.__class__.__name__}(...)")
                else:
                    node = Node(
                        open_brace=f"{obj.__class__.__name__}(",
                        close_brace=")",
                        children=children,
                        last=root,
                        empty=f"{obj.__class__.__name__}()",
                    )
    
                    for last, field in loop_last(
                        field
                        for field in fields(obj)
                        if field.repr and hasattr(obj, field.name)
                    ):
                        child_node = _traverse(getattr(obj, field.name), depth=depth + 1)
                        child_node.key_repr = field.name
                        child_node.last = last
                        child_node.key_separator = "="
                        append(child_node)
    
                pop_visited(obj_id)
            elif _is_namedtuple(obj) and _has_default_namedtuple_repr(obj):
                push_visited(obj_id)
                class_name = obj.__class__.__name__
                if reached_max_depth:
                    # If we've reached the max depth, we still show the class name, but not its contents
                    node = Node(
                        value_repr=f"{class_name}(...)",
                    )
                else:
                    children = []
                    append = children.append
                    node = Node(
                        open_brace=f"{class_name}(",
                        close_brace=")",
                        children=children,
                        empty=f"{class_name}()",
                    )
                    for last, (key, value) in loop_last(obj._asdict().items()):
                        child_node = _traverse(value, depth=depth + 1)
                        child_node.key_repr = key
                        child_node.last = last
                        child_node.key_separator = "="
                        append(child_node)
                pop_visited(obj_id)
            elif _safe_isinstance(obj, _CONTAINERS):
                for container_type in _CONTAINERS:
                    if _safe_isinstance(obj, container_type):
                        obj_type = container_type
                        break
    
                push_visited(obj_id)
    
                open_brace, close_brace, empty = _BRACES[obj_type](obj)
    
                if reached_max_depth:
                    node = Node(value_repr=f"{open_brace}...{close_brace}")
                elif obj_type.__repr__ != type(obj).__repr__:
                    node = Node(value_repr=to_repr(obj), last=root)
                elif obj:
                    children = []
                    node = Node(
                        open_brace=open_brace,
                        close_brace=close_brace,
                        children=children,
                        last=root,
                    )
                    append = children.append
                    num_items = len(obj)
                    last_item_index = num_items - 1
    
                    if _safe_isinstance(obj, _MAPPING_CONTAINERS):
                        iter_items = iter(obj.items())
                        if max_length is not None:
                            iter_items = islice(iter_items, max_length)
                        for index, (key, child) in enumerate(iter_items):
                            child_node = _traverse(child, depth=depth + 1)
                            child_node.key_repr = to_repr(key)
                            child_node.last = index == last_item_index
                            append(child_node)
                    else:
                        iter_values = iter(obj)
                        if max_length is not None:
                            iter_values = islice(iter_values, max_length)
                        for index, child in enumerate(iter_values):
                            child_node = _traverse(child, depth=depth + 1)
                            child_node.last = index == last_item_index
                            append(child_node)
                    if max_length is not None and num_items > max_length:
                        append(Node(value_repr=f"... +{num_items - max_length}", last=True))
                else:
                    node = Node(empty=empty, children=[], last=root)
    
                pop_visited(obj_id)
            else:
                node = Node(value_repr=to_repr(obj), last=root)
            node.is_tuple = type(obj) == tuple
            node.is_namedtuple = _is_namedtuple(obj)
            return node
    
>       node = _traverse(_object, root=True)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/rich/pretty.py:874: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

obj = <[DetachedInstanceError('Instance <ThTransHead at 0x11bae06e0> is not bound to a Session; attribute refresh operation cannot proceed') raised in repr()] ThTransHead object at 0x11bae06e0>
root = True, depth = 0

    def _traverse(obj: Any, root: bool = False, depth: int = 0) -> Node:
        """Walk the object depth first."""
    
        obj_id = id(obj)
        if obj_id in visited_ids:
            # Recursion detected
            return Node(value_repr="...")
    
        obj_type = type(obj)
        children: List[Node]
        reached_max_depth = max_depth is not None and depth >= max_depth
    
        def iter_rich_args(rich_args: Any) -> Iterable[Union[Any, Tuple[str, Any]]]:
            for arg in rich_args:
                if _safe_isinstance(arg, tuple):
                    if len(arg) == 3:
                        key, child, default = arg
                        if default == child:
                            continue
                        yield key, child
                    elif len(arg) == 2:
                        key, child = arg
                        yield key, child
                    elif len(arg) == 1:
                        yield arg[0]
                else:
                    yield arg
    
        try:
            fake_attributes = hasattr(
                obj, "awehoi234_wdfjwljet234_234wdfoijsdfmmnxpi492"
            )
        except Exception:
            fake_attributes = False
    
        rich_repr_result: Optional[RichReprResult] = None
        if not fake_attributes:
            try:
                if hasattr(obj, "__rich_repr__") and not isclass(obj):
                    rich_repr_result = obj.__rich_repr__()
            except Exception:
                pass
    
        if rich_repr_result is not None:
            push_visited(obj_id)
            angular = getattr(obj.__rich_repr__, "angular", False)
            args = list(iter_rich_args(rich_repr_result))
            class_name = obj.__class__.__name__
    
            if args:
                children = []
                append = children.append
    
                if reached_max_depth:
                    if angular:
                        node = Node(value_repr=f"<{class_name}...>")
                    else:
                        node = Node(value_repr=f"{class_name}(...)")
                else:
                    if angular:
                        node = Node(
                            open_brace=f"<{class_name} ",
                            close_brace=">",
                            children=children,
                            last=root,
                            separator=" ",
                        )
                    else:
                        node = Node(
                            open_brace=f"{class_name}(",
                            close_brace=")",
                            children=children,
                            last=root,
                        )
                    for last, arg in loop_last(args):
                        if _safe_isinstance(arg, tuple):
                            key, child = arg
                            child_node = _traverse(child, depth=depth + 1)
                            child_node.last = last
                            child_node.key_repr = key
                            child_node.key_separator = "="
                            append(child_node)
                        else:
                            child_node = _traverse(arg, depth=depth + 1)
                            child_node.last = last
                            append(child_node)
            else:
                node = Node(
                    value_repr=f"<{class_name}>" if angular else f"{class_name}()",
                    children=[],
                    last=root,
                )
            pop_visited(obj_id)
        elif _is_attr_object(obj) and not fake_attributes:
            push_visited(obj_id)
            children = []
            append = children.append
    
            attr_fields = _get_attr_fields(obj)
            if attr_fields:
                if reached_max_depth:
                    node = Node(value_repr=f"{obj.__class__.__name__}(...)")
                else:
                    node = Node(
                        open_brace=f"{obj.__class__.__name__}(",
                        close_brace=")",
                        children=children,
                        last=root,
                    )
    
                    def iter_attrs() -> (
                        Iterable[Tuple[str, Any, Optional[Callable[[Any], str]]]]
                    ):
                        """Iterate over attr fields and values."""
                        for attr in attr_fields:
                            if attr.repr:
                                try:
                                    value = getattr(obj, attr.name)
                                except Exception as error:
                                    # Can happen, albeit rarely
                                    yield (attr.name, error, None)
                                else:
                                    yield (
                                        attr.name,
                                        value,
                                        attr.repr if callable(attr.repr) else None,
                                    )
    
                    for last, (name, value, repr_callable) in loop_last(iter_attrs()):
                        if repr_callable:
                            child_node = Node(value_repr=str(repr_callable(value)))
                        else:
                            child_node = _traverse(value, depth=depth + 1)
                        child_node.last = last
                        child_node.key_repr = name
                        child_node.key_separator = "="
                        append(child_node)
            else:
                node = Node(
                    value_repr=f"{obj.__class__.__name__}()", children=[], last=root
                )
            pop_visited(obj_id)
        elif (
            is_dataclass(obj)
            and not _safe_isinstance(obj, type)
            and not fake_attributes
            and _is_dataclass_repr(obj)
        ):
            push_visited(obj_id)
            children = []
            append = children.append
            if reached_max_depth:
                node = Node(value_repr=f"{obj.__class__.__name__}(...)")
            else:
                node = Node(
                    open_brace=f"{obj.__class__.__name__}(",
                    close_brace=")",
                    children=children,
                    last=root,
                    empty=f"{obj.__class__.__name__}()",
                )
    
                for last, field in loop_last(
                    field
                    for field in fields(obj)
                    if field.repr and hasattr(obj, field.name)
                ):
>                   child_node = _traverse(getattr(obj, field.name), depth=depth + 1)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/rich/pretty.py:788: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

obj = <[DetachedInstanceError('Instance <ThContent at 0x11bae1be0> is not bound to a Session; attribute refresh operation cannot proceed') raised in repr()] ThContent object at 0x11bae1be0>
root = False, depth = 1

    def _traverse(obj: Any, root: bool = False, depth: int = 0) -> Node:
        """Walk the object depth first."""
    
        obj_id = id(obj)
        if obj_id in visited_ids:
            # Recursion detected
            return Node(value_repr="...")
    
        obj_type = type(obj)
        children: List[Node]
        reached_max_depth = max_depth is not None and depth >= max_depth
    
        def iter_rich_args(rich_args: Any) -> Iterable[Union[Any, Tuple[str, Any]]]:
            for arg in rich_args:
                if _safe_isinstance(arg, tuple):
                    if len(arg) == 3:
                        key, child, default = arg
                        if default == child:
                            continue
                        yield key, child
                    elif len(arg) == 2:
                        key, child = arg
                        yield key, child
                    elif len(arg) == 1:
                        yield arg[0]
                else:
                    yield arg
    
        try:
            fake_attributes = hasattr(
                obj, "awehoi234_wdfjwljet234_234wdfoijsdfmmnxpi492"
            )
        except Exception:
            fake_attributes = False
    
        rich_repr_result: Optional[RichReprResult] = None
        if not fake_attributes:
            try:
                if hasattr(obj, "__rich_repr__") and not isclass(obj):
                    rich_repr_result = obj.__rich_repr__()
            except Exception:
                pass
    
        if rich_repr_result is not None:
            push_visited(obj_id)
            angular = getattr(obj.__rich_repr__, "angular", False)
            args = list(iter_rich_args(rich_repr_result))
            class_name = obj.__class__.__name__
    
            if args:
                children = []
                append = children.append
    
                if reached_max_depth:
                    if angular:
                        node = Node(value_repr=f"<{class_name}...>")
                    else:
                        node = Node(value_repr=f"{class_name}(...)")
                else:
                    if angular:
                        node = Node(
                            open_brace=f"<{class_name} ",
                            close_brace=">",
                            children=children,
                            last=root,
                            separator=" ",
                        )
                    else:
                        node = Node(
                            open_brace=f"{class_name}(",
                            close_brace=")",
                            children=children,
                            last=root,
                        )
                    for last, arg in loop_last(args):
                        if _safe_isinstance(arg, tuple):
                            key, child = arg
                            child_node = _traverse(child, depth=depth + 1)
                            child_node.last = last
                            child_node.key_repr = key
                            child_node.key_separator = "="
                            append(child_node)
                        else:
                            child_node = _traverse(arg, depth=depth + 1)
                            child_node.last = last
                            append(child_node)
            else:
                node = Node(
                    value_repr=f"<{class_name}>" if angular else f"{class_name}()",
                    children=[],
                    last=root,
                )
            pop_visited(obj_id)
        elif _is_attr_object(obj) and not fake_attributes:
            push_visited(obj_id)
            children = []
            append = children.append
    
            attr_fields = _get_attr_fields(obj)
            if attr_fields:
                if reached_max_depth:
                    node = Node(value_repr=f"{obj.__class__.__name__}(...)")
                else:
                    node = Node(
                        open_brace=f"{obj.__class__.__name__}(",
                        close_brace=")",
                        children=children,
                        last=root,
                    )
    
                    def iter_attrs() -> (
                        Iterable[Tuple[str, Any, Optional[Callable[[Any], str]]]]
                    ):
                        """Iterate over attr fields and values."""
                        for attr in attr_fields:
                            if attr.repr:
                                try:
                                    value = getattr(obj, attr.name)
                                except Exception as error:
                                    # Can happen, albeit rarely
                                    yield (attr.name, error, None)
                                else:
                                    yield (
                                        attr.name,
                                        value,
                                        attr.repr if callable(attr.repr) else None,
                                    )
    
                    for last, (name, value, repr_callable) in loop_last(iter_attrs()):
                        if repr_callable:
                            child_node = Node(value_repr=str(repr_callable(value)))
                        else:
                            child_node = _traverse(value, depth=depth + 1)
                        child_node.last = last
                        child_node.key_repr = name
                        child_node.key_separator = "="
                        append(child_node)
            else:
                node = Node(
                    value_repr=f"{obj.__class__.__name__}()", children=[], last=root
                )
            pop_visited(obj_id)
        elif (
            is_dataclass(obj)
            and not _safe_isinstance(obj, type)
            and not fake_attributes
            and _is_dataclass_repr(obj)
        ):
            push_visited(obj_id)
            children = []
            append = children.append
            if reached_max_depth:
                node = Node(value_repr=f"{obj.__class__.__name__}(...)")
            else:
                node = Node(
                    open_brace=f"{obj.__class__.__name__}(",
                    close_brace=")",
                    children=children,
                    last=root,
                    empty=f"{obj.__class__.__name__}()",
                )
    
>               for last, field in loop_last(
                    field
                    for field in fields(obj)
                    if field.repr and hasattr(obj, field.name)
                ):

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/rich/pretty.py:783: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

values = <generator object traverse.<locals>._traverse.<locals>.<genexpr> at 0x11baf5700>

    def loop_last(values: Iterable[T]) -> Iterable[Tuple[bool, T]]:
        """Iterate and generate a tuple with a flag for last value."""
        iter_values = iter(values)
        try:
            previous_value = next(iter_values)
        except StopIteration:
            return
>       for value in iter_values:
                     ^^^^^^^^^^^

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/rich/_loop.py:25: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <tuple_iterator object at 0x11bae2c80>

    for last, field in loop_last(
        field
        for field in fields(obj)
>       if field.repr and hasattr(obj, field.name)
                          ^^^^^^^^^^^^^^^^^^^^^^^^
    ):

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/rich/pretty.py:786: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.attributes.InstrumentedAttribute object at 0x1140919e0>
instance = <[DetachedInstanceError('Instance <ThContent at 0x11bae1be0> is not bound to a Session; attribute refresh operation cannot proceed') raised in repr()] ThContent object at 0x11bae1be0>
owner = <class 'trans_hub.infrastructure.db._schema.ThContent'>

    def __get__(
        self, instance: Optional[object], owner: Any
    ) -> Union[InstrumentedAttribute[_T_co], _T_co]:
        if instance is None:
            return self
    
        dict_ = instance_dict(instance)
        if self.impl.supports_population and self.key in dict_:
            return dict_[self.key]  # type: ignore[no-any-return]
        else:
            try:
                state = instance_state(instance)
            except AttributeError as err:
                raise orm_exc.UnmappedInstanceError(instance) from err
>           return self.impl.get(state, dict_)  # type: ignore[no-any-return]
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/sqlalchemy/orm/attributes.py:569: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.attributes.CollectionAttributeImpl object at 0x11b961430>
state = <sqlalchemy.orm.state.InstanceState object at 0x11bae4b90>
dict_ = {'_sa_instance_state': <sqlalchemy.orm.state.InstanceState object at 0x11bae4b90>}
passive = symbol('PASSIVE_OFF')

    def get(
        self,
        state: InstanceState[Any],
        dict_: _InstanceDict,
        passive: PassiveFlag = PASSIVE_OFF,
    ) -> Any:
        """Retrieve a value from the given object.
        If a callable is assembled on this object's attribute, and
        passive is False, the callable will be executed and the
        resulting value will be set as the new value for this attribute.
        """
        if self.key in dict_:
            return dict_[self.key]
        else:
            # if history present, don't load
            key = self.key
            if (
                key not in state.committed_state
                or state.committed_state[key] is NO_VALUE
            ):
                if not passive & CALLABLES_OK:
                    return PASSIVE_NO_RESULT
    
>               value = self._fire_loader_callables(state, key, passive)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/sqlalchemy/orm/attributes.py:1096: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.attributes.CollectionAttributeImpl object at 0x11b961430>
state = <sqlalchemy.orm.state.InstanceState object at 0x11bae4b90>
key = 'trans_heads', passive = symbol('PASSIVE_OFF')

    def _fire_loader_callables(
        self, state: InstanceState[Any], key: str, passive: PassiveFlag
    ) -> Any:
        if (
            self.accepts_scalar_loader
            and self.load_on_unexpire
            and key in state.expired_attributes
        ):
            return state._load_expired(state, passive)
        elif key in state.callables:
            callable_ = state.callables[key]
            return callable_(state, passive)
        elif self.callable_:
>           return self.callable_(state, passive)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/sqlalchemy/orm/attributes.py:1131: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.strategies.LazyLoader object at 0x11b9b4660>
state = <sqlalchemy.orm.state.InstanceState object at 0x11bae4b90>
passive = symbol('PASSIVE_OFF'), loadopt = None, extra_criteria = ()
extra_options = (), alternate_effective_path = None
execution_options = immutabledict({})

    def _load_for_state(
        self,
        state,
        passive,
        loadopt=None,
        extra_criteria=(),
        extra_options=(),
        alternate_effective_path=None,
        execution_options=util.EMPTY_DICT,
    ):
        if not state.key and (
            (
                not self.parent_property.load_on_pending
                and not state._load_pending
            )
            or not state.session_id
        ):
            return LoaderCallableStatus.ATTR_EMPTY
    
        pending = not state.key
        primary_key_identity = None
    
        use_get = self.use_get and (not loadopt or not loadopt._extra_criteria)
    
        if (not passive & PassiveFlag.SQL_OK and not use_get) or (
            not passive & attributes.NON_PERSISTENT_OK and pending
        ):
            return LoaderCallableStatus.PASSIVE_NO_RESULT
    
        if (
            # we were given lazy="raise"
            self._raise_always
            # the no_raise history-related flag was not passed
            and not passive & PassiveFlag.NO_RAISE
            and (
                # if we are use_get and related_object_ok is disabled,
                # which means we are at most looking in the identity map
                # for history purposes or otherwise returning
                # PASSIVE_NO_RESULT, don't raise.  This is also a
                # history-related flag
                not use_get
                or passive & PassiveFlag.RELATED_OBJECT_OK
            )
        ):
            self._invoke_raise_load(state, passive, "raise")
    
        session = _state_session(state)
        if not session:
            if passive & PassiveFlag.NO_RAISE:
                return LoaderCallableStatus.PASSIVE_NO_RESULT
    
            raise orm_exc.DetachedInstanceError(
                "Parent instance %s is not bound to a Session; "
                "lazy load operation of attribute '%s' cannot proceed"
                % (orm_util.state_str(state), self.key)
            )
    
        # if we have a simple primary key load, check the
        # identity map without generating a Query at all
        if use_get:
            primary_key_identity = self._get_ident_for_use_get(
                session, state, passive
            )
            if LoaderCallableStatus.PASSIVE_NO_RESULT in primary_key_identity:
                return LoaderCallableStatus.PASSIVE_NO_RESULT
            elif LoaderCallableStatus.NEVER_SET in primary_key_identity:
                return LoaderCallableStatus.NEVER_SET
    
            # test for None alone in primary_key_identity based on
            # allow_partial_pks preference.   PASSIVE_NO_RESULT and NEVER_SET
            # have already been tested above
            if not self.mapper.allow_partial_pks:
                if _none_only_set.intersection(primary_key_identity):
                    return None
            else:
                if _none_only_set.issuperset(primary_key_identity):
                    return None
    
            if (
                self.key in state.dict
                and not passive & PassiveFlag.DEFERRED_HISTORY_LOAD
            ):
                return LoaderCallableStatus.ATTR_WAS_SET
    
            # look for this identity in the identity map.  Delegate to the
            # Query class in use, as it may have special rules for how it
            # does this, including how it decides what the correct
            # identity_token would be for this identity.
    
            instance = session._identity_lookup(
                self.entity,
                primary_key_identity,
                passive=passive,
                lazy_loaded_from=state,
            )
    
            if instance is not None:
                if instance is LoaderCallableStatus.PASSIVE_CLASS_MISMATCH:
                    return None
                else:
                    return instance
            elif (
                not passive & PassiveFlag.SQL_OK
                or not passive & PassiveFlag.RELATED_OBJECT_OK
            ):
                return LoaderCallableStatus.PASSIVE_NO_RESULT
    
>       return self._emit_lazyload(
            session,
            state,
            primary_key_identity,
            passive,
            loadopt,
            extra_criteria,
            extra_options,
            alternate_effective_path,
            execution_options,
        )

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/sqlalchemy/orm/strategies.py:978: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.strategies.LazyLoader object at 0x11b9b4660>
session = <sqlalchemy.orm.session.Session object at 0x11bab6750>
state = <sqlalchemy.orm.state.InstanceState object at 0x11bae4b90>
primary_key_identity = None, passive = symbol('PASSIVE_OFF'), loadopt = None
extra_criteria = (), extra_options = (), alternate_effective_path = None
execution_options = {'_sa_orm_load_options': default_load_options(_invoke_all_eagers=False, _lazy_loaded_from=<sqlalchemy.orm.state.InstanceState object at 0x11bae4b90>)}

    @util.preload_module("sqlalchemy.orm.strategy_options")
    def _emit_lazyload(
        self,
        session,
        state,
        primary_key_identity,
        passive,
        loadopt,
        extra_criteria,
        extra_options,
        alternate_effective_path,
        execution_options,
    ):
        strategy_options = util.preloaded.orm_strategy_options
    
        clauseelement = self.entity.__clause_element__()
        stmt = Select._create_raw_select(
            _raw_columns=[clauseelement],
            _propagate_attrs=clauseelement._propagate_attrs,
            _label_style=LABEL_STYLE_TABLENAME_PLUS_COL,
            _compile_options=ORMCompileState.default_compile_options,
        )
        load_options = QueryContext.default_load_options
    
        load_options += {
            "_invoke_all_eagers": False,
            "_lazy_loaded_from": state,
        }
    
        if self.parent_property.secondary is not None:
            stmt = stmt.select_from(
                self.mapper, self.parent_property.secondary
            )
    
        pending = not state.key
    
        # don't autoflush on pending
        if pending or passive & attributes.NO_AUTOFLUSH:
            stmt._execution_options = util.immutabledict({"autoflush": False})
    
        use_get = self.use_get
    
        if state.load_options or (loadopt and loadopt._extra_criteria):
            if alternate_effective_path is None:
                effective_path = state.load_path[self.parent_property]
            else:
                effective_path = alternate_effective_path[self.parent_property]
    
            opts = state.load_options
    
            if loadopt and loadopt._extra_criteria:
                use_get = False
                opts += (
                    orm_util.LoaderCriteriaOption(self.entity, extra_criteria),
                )
    
            stmt._with_options = opts
        elif alternate_effective_path is None:
            # this path is used if there are not already any options
            # in the query, but an event may want to add them
            effective_path = state.mapper._path_registry[self.parent_property]
        else:
            # added by immediateloader
            effective_path = alternate_effective_path[self.parent_property]
    
        if extra_options:
            stmt._with_options += extra_options
    
        stmt._compile_options += {"_current_path": effective_path}
    
        if use_get:
            if self._raise_on_sql and not passive & PassiveFlag.NO_RAISE:
                self._invoke_raise_load(state, passive, "raise_on_sql")
    
            return loading.load_on_pk_identity(
                session,
                stmt,
                primary_key_identity,
                load_options=load_options,
                execution_options=execution_options,
            )
    
        if self._order_by:
            stmt._order_by_clauses = self._order_by
    
        def _lazyload_reverse(compile_context):
            for rev in self.parent_property._reverse_property:
                # reverse props that are MANYTOONE are loading *this*
                # object from get(), so don't need to eager out to those.
                if (
                    rev.direction is interfaces.MANYTOONE
                    and rev._use_get
                    and not isinstance(rev.strategy, LazyLoader)
                ):
                    strategy_options.Load._construct_for_existing_path(
                        compile_context.compile_options._current_path[
                            rev.parent
                        ]
                    ).lazyload(rev).process_compile_state(compile_context)
    
        stmt._with_context_options += (
            (_lazyload_reverse, self.parent_property),
        )
    
        lazy_clause, params = self._generate_lazy_clause(state, passive)
    
        if execution_options:
            execution_options = util.EMPTY_DICT.merge_with(
                execution_options,
                {
                    "_sa_orm_load_options": load_options,
                },
            )
        else:
            execution_options = {
                "_sa_orm_load_options": load_options,
            }
    
        if (
            self.key in state.dict
            and not passive & PassiveFlag.DEFERRED_HISTORY_LOAD
        ):
            return LoaderCallableStatus.ATTR_WAS_SET
    
        if pending:
            if util.has_intersection(orm_util._none_set, params.values()):
                return None
    
        elif util.has_intersection(orm_util._never_set, params.values()):
            return None
    
        if self._raise_on_sql and not passive & PassiveFlag.NO_RAISE:
            self._invoke_raise_load(state, passive, "raise_on_sql")
    
        stmt._where_criteria = (lazy_clause,)
    
>       result = session.execute(
            stmt, params, execution_options=execution_options
        )

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/sqlalchemy/orm/strategies.py:1141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x11bab6750>
statement = <sqlalchemy.sql.selectable.Select object at 0x11bae29c0>
params = {'%(4758021344 param)s': '110199d4-1732-4b66-826e-cf7dbbe68391'}

    def execute(
        self,
        statement: Executable,
        params: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: OrmExecuteOptionsParameter = util.EMPTY_DICT,
        bind_arguments: Optional[_BindArguments] = None,
        _parent_execute_state: Optional[Any] = None,
        _add_event: Optional[Any] = None,
    ) -> Result[Any]:
        r"""Execute a SQL expression construct.
    
        Returns a :class:`_engine.Result` object representing
        results of the statement execution.
    
        E.g.::
    
            from sqlalchemy import select
    
            result = session.execute(select(User).where(User.id == 5))
    
        The API contract of :meth:`_orm.Session.execute` is similar to that
        of :meth:`_engine.Connection.execute`, the :term:`2.0 style` version
        of :class:`_engine.Connection`.
    
        .. versionchanged:: 1.4 the :meth:`_orm.Session.execute` method is
           now the primary point of ORM statement execution when using
           :term:`2.0 style` ORM usage.
    
        :param statement:
            An executable statement (i.e. an :class:`.Executable` expression
            such as :func:`_expression.select`).
    
        :param params:
            Optional dictionary, or list of dictionaries, containing
            bound parameter values.   If a single dictionary, single-row
            execution occurs; if a list of dictionaries, an
            "executemany" will be invoked.  The keys in each dictionary
            must correspond to parameter names present in the statement.
    
        :param execution_options: optional dictionary of execution options,
         which will be associated with the statement execution.  This
         dictionary can provide a subset of the options that are accepted
         by :meth:`_engine.Connection.execution_options`, and may also
         provide additional options understood only in an ORM context.
    
         .. seealso::
    
            :ref:`orm_queryguide_execution_options` - ORM-specific execution
            options
    
        :param bind_arguments: dictionary of additional arguments to determine
         the bind.  May include "mapper", "bind", or other custom arguments.
         Contents of this dictionary are passed to the
         :meth:`.Session.get_bind` method.
    
        :return: a :class:`_engine.Result` object.
    
    
        """
>       return self._execute_internal(
            statement,
            params,
            execution_options=execution_options,
            bind_arguments=bind_arguments,
            _parent_execute_state=_parent_execute_state,
            _add_event=_add_event,
        )

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/sqlalchemy/orm/session.py:2365: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.session.Session object at 0x11bab6750>
statement = <sqlalchemy.sql.selectable.Select object at 0x11bae29c0>
params = {'%(4758021344 param)s': '110199d4-1732-4b66-826e-cf7dbbe68391'}

    def _execute_internal(
        self,
        statement: Executable,
        params: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: OrmExecuteOptionsParameter = util.EMPTY_DICT,
        bind_arguments: Optional[_BindArguments] = None,
        _parent_execute_state: Optional[Any] = None,
        _add_event: Optional[Any] = None,
        _scalar_result: bool = False,
    ) -> Any:
        statement = coercions.expect(roles.StatementRole, statement)
    
        if not bind_arguments:
            bind_arguments = {}
        else:
            bind_arguments = dict(bind_arguments)
    
        if (
            statement._propagate_attrs.get("compile_state_plugin", None)
            == "orm"
        ):
            compile_state_cls = CompileState._get_plugin_class_for_plugin(
                statement, "orm"
            )
            if TYPE_CHECKING:
                assert isinstance(
                    compile_state_cls, context.AbstractORMCompileState
                )
        else:
            compile_state_cls = None
            bind_arguments.setdefault("clause", statement)
    
        execution_options = util.coerce_to_immutabledict(execution_options)
    
        if _parent_execute_state:
            events_todo = _parent_execute_state._remaining_events()
        else:
            events_todo = self.dispatch.do_orm_execute
            if _add_event:
                events_todo = list(events_todo) + [_add_event]
    
        if events_todo:
            if compile_state_cls is not None:
                # for event handlers, do the orm_pre_session_exec
                # pass ahead of the event handlers, so that things like
                # .load_options, .update_delete_options etc. are populated.
                # is_pre_event=True allows the hook to hold off on things
                # it doesn't want to do twice, including autoflush as well
                # as "pre fetch" for DML, etc.
                (
                    statement,
                    execution_options,
                ) = compile_state_cls.orm_pre_session_exec(
                    self,
                    statement,
                    params,
                    execution_options,
                    bind_arguments,
                    True,
                )
    
            orm_exec_state = ORMExecuteState(
                self,
                statement,
                params,
                execution_options,
                bind_arguments,
                compile_state_cls,
                events_todo,
            )
            for idx, fn in enumerate(events_todo):
                orm_exec_state._starting_event_idx = idx
                fn_result: Optional[Result[Any]] = fn(orm_exec_state)
                if fn_result:
                    if _scalar_result:
                        return fn_result.scalar()
                    else:
                        return fn_result
    
            statement = orm_exec_state.statement
            execution_options = orm_exec_state.local_execution_options
    
        if compile_state_cls is not None:
            # now run orm_pre_session_exec() "for real".   if there were
            # event hooks, this will re-run the steps that interpret
            # new execution_options into load_options / update_delete_options,
            # which we assume the event hook might have updated.
            # autoflush will also be invoked in this step if enabled.
            (
                statement,
                execution_options,
            ) = compile_state_cls.orm_pre_session_exec(
                self,
                statement,
                params,
                execution_options,
                bind_arguments,
                False,
            )
    
        bind = self.get_bind(**bind_arguments)
    
        conn = self._connection_for_bind(bind)
    
        if _scalar_result and not compile_state_cls:
            if TYPE_CHECKING:
                params = cast(_CoreSingleExecuteParams, params)
            return conn.scalar(
                statement, params or {}, execution_options=execution_options
            )
    
        if compile_state_cls:
>           result: Result[Any] = compile_state_cls.orm_execute_statement(
                self,
                statement,
                params or {},
                execution_options,
                bind_arguments,
                conn,
            )

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/sqlalchemy/orm/session.py:2251: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.orm.context.ORMSelectCompileState'>
session = <sqlalchemy.orm.session.Session object at 0x11bab6750>
statement = <sqlalchemy.sql.selectable.Select object at 0x11bae29c0>
params = {'%(4758021344 param)s': '110199d4-1732-4b66-826e-cf7dbbe68391'}
execution_options = immutabledict({'_sa_orm_load_options': default_load_options(_invoke_all_eagers=False, _lazy_loaded_from=<sqlalchemy.orm.state.InstanceState object at 0x11bae4b90>), '_result_disable_adapt_to_context': True})
bind_arguments = {'clause': <sqlalchemy.sql.selectable.Select object at 0x11bae29c0>, 'mapper': <Mapper at 0x113b59310; ThTransHead>}
conn = <sqlalchemy.engine.base.Connection object at 0x11bab6060>

    @classmethod
    def orm_execute_statement(
        cls,
        session,
        statement,
        params,
        execution_options,
        bind_arguments,
        conn,
    ) -> Result:
>       result = conn.execute(
            statement, params or {}, execution_options=execution_options
        )

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/sqlalchemy/orm/context.py:306: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x11bab6060>
statement = <sqlalchemy.sql.selectable.Select object at 0x11bae29c0>
parameters = {'%(4758021344 param)s': '110199d4-1732-4b66-826e-cf7dbbe68391'}

    def execute(
        self,
        statement: Executable,
        parameters: Optional[_CoreAnyExecuteParams] = None,
        *,
        execution_options: Optional[CoreExecuteOptionsParameter] = None,
    ) -> CursorResult[Any]:
        r"""Executes a SQL statement construct and returns a
        :class:`_engine.CursorResult`.
    
        :param statement: The statement to be executed.  This is always
         an object that is in both the :class:`_expression.ClauseElement` and
         :class:`_expression.Executable` hierarchies, including:
    
         * :class:`_expression.Select`
         * :class:`_expression.Insert`, :class:`_expression.Update`,
           :class:`_expression.Delete`
         * :class:`_expression.TextClause` and
           :class:`_expression.TextualSelect`
         * :class:`_schema.DDL` and objects which inherit from
           :class:`_schema.ExecutableDDLElement`
    
        :param parameters: parameters which will be bound into the statement.
         This may be either a dictionary of parameter names to values,
         or a mutable sequence (e.g. a list) of dictionaries.  When a
         list of dictionaries is passed, the underlying statement execution
         will make use of the DBAPI ``cursor.executemany()`` method.
         When a single dictionary is passed, the DBAPI ``cursor.execute()``
         method will be used.
    
        :param execution_options: optional dictionary of execution options,
         which will be associated with the statement execution.  This
         dictionary can provide a subset of the options that are accepted
         by :meth:`_engine.Connection.execution_options`.
    
        :return: a :class:`_engine.Result` object.
    
        """
        distilled_parameters = _distill_params_20(parameters)
        try:
            meth = statement._execute_on_connection
        except AttributeError as err:
            raise exc.ObjectNotExecutableError(statement) from err
        else:
>           return meth(
                self,
                distilled_parameters,
                execution_options or NO_OPTIONS,
            )

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1413: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.sql.selectable.Select object at 0x11bae29c0>
connection = <sqlalchemy.engine.base.Connection object at 0x11bab6060>
distilled_params = [{'%(4758021344 param)s': '110199d4-1732-4b66-826e-cf7dbbe68391'}]
execution_options = immutabledict({'_sa_orm_load_options': default_load_options(_invoke_all_eagers=False, _lazy_loaded_from=<sqlalchemy.orm.state.InstanceState object at 0x11bae4b90>), '_result_disable_adapt_to_context': True})

    def _execute_on_connection(
        self,
        connection: Connection,
        distilled_params: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> Result[Any]:
        if self.supports_execution:
            if TYPE_CHECKING:
                assert isinstance(self, Executable)
>           return connection._execute_clauseelement(
                self, distilled_params, execution_options
            )

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:526: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x11bab6060>
elem = <sqlalchemy.sql.selectable.Select object at 0x11bae29c0>
distilled_parameters = [{'%(4758021344 param)s': '110199d4-1732-4b66-826e-cf7dbbe68391'}]
execution_options = immutabledict({'_sa_orm_load_options': default_load_options(_invoke_all_eagers=False, _lazy_loaded_from=<sqlalchemy.orm.state.InstanceState object at 0x11bae4b90>), '_result_disable_adapt_to_context': True})

    def _execute_clauseelement(
        self,
        elem: Executable,
        distilled_parameters: _CoreMultiExecuteParams,
        execution_options: CoreExecuteOptionsParameter,
    ) -> CursorResult[Any]:
        """Execute a sql.ClauseElement object."""
    
        execution_options = elem._execution_options.merge_with(
            self._execution_options, execution_options
        )
    
        has_events = self._has_events or self.engine._has_events
        if has_events:
            (
                elem,
                distilled_parameters,
                event_multiparams,
                event_params,
            ) = self._invoke_before_exec_event(
                elem, distilled_parameters, execution_options
            )
    
        if distilled_parameters:
            # ensure we don't retain a link to the view object for keys()
            # which links to the values, which we don't want to cache
            keys = sorted(distilled_parameters[0])
            for_executemany = len(distilled_parameters) > 1
        else:
            keys = []
            for_executemany = False
    
        dialect = self.dialect
    
        schema_translate_map = execution_options.get(
            "schema_translate_map", None
        )
    
        compiled_cache: Optional[CompiledCacheType] = execution_options.get(
            "compiled_cache", self.engine._compiled_cache
        )
    
        compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(
            dialect=dialect,
            compiled_cache=compiled_cache,
            column_keys=keys,
            for_executemany=for_executemany,
            schema_translate_map=schema_translate_map,
            linting=self.dialect.compiler_linting | compiler.WARN_LINTING,
        )
>       ret = self._execute_context(
            dialect,
            dialect.execution_ctx_cls._init_compiled,
            compiled_sql,
            distilled_parameters,
            execution_options,
            compiled_sql,
            distilled_parameters,
            elem,
            extracted_params,
            cache_hit=cache_hit,
        )

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1635: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x11bab6060>
dialect = <sqlalchemy.dialects.postgresql.psycopg.PGDialectAsync_psycopg object at 0x1127b31d0>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.postgresql.psycopg.PGExecutionContext_psycopg'>>
statement = <sqlalchemy.dialects.postgresql.psycopg.PGCompiler_psycopg object at 0x11bae1d90>
parameters = [{'%(4758021344 param)s': '110199d4-1732-4b66-826e-cf7dbbe68391'}]
execution_options = immutabledict({'_sa_orm_load_options': default_load_options(_invoke_all_eagers=False, _lazy_loaded_from=<sqlalchemy.orm.state.InstanceState object at 0x11bae4b90>), '_result_disable_adapt_to_context': True})
args = (<sqlalchemy.dialects.postgresql.psycopg.PGCompiler_psycopg object at 0x11bae1d90>, [{'%(4758021344 param)s': '110199d...emy.sql.selectable.Select object at 0x11bae29c0>, [AnnotatedBindParameter('%(4758021344 param)s', None, type_=Text())])
kw = {'cache_hit': <CacheStats.CACHE_MISS: 1>}, yp = None
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x11ba9eff0>
context = <sqlalchemy.dialects.postgresql.psycopg.PGExecutionContext_psycopg object at 0x11bae19a0>

    def _execute_context(
        self,
        dialect: Dialect,
        constructor: Callable[..., ExecutionContext],
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
        execution_options: _ExecuteOptions,
        *args: Any,
        **kw: Any,
    ) -> CursorResult[Any]:
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""
    
        if execution_options:
            yp = execution_options.get("yield_per", None)
            if yp:
                execution_options = execution_options.union(
                    {"stream_results": True, "max_row_buffer": yp}
                )
        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()
    
            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, str(statement), parameters, None, None
            )
    
        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()
    
        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)
    
        if self._transaction is None:
            self._autobegin()
    
        context.pre_exec()
    
        if context.execute_style is ExecuteStyle.INSERTMANYVALUES:
            return self._exec_insertmany_context(dialect, context)
        else:
>           return self._exec_single_context(
                dialect, context, statement, parameters
            )

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1840: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x11bab6060>
dialect = <sqlalchemy.dialects.postgresql.psycopg.PGDialectAsync_psycopg object at 0x1127b31d0>
context = <sqlalchemy.dialects.postgresql.psycopg.PGExecutionContext_psycopg object at 0x11bae19a0>
statement = <sqlalchemy.dialects.postgresql.psycopg.PGCompiler_psycopg object at 0x11bae1d90>
parameters = [{'param_1': '110199d4-1732-4b66-826e-cf7dbbe68391'}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )
    
            if self._has_events or self.engine._has_events:
                self.dispatch.after_cursor_execute(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
            context.post_exec()
    
            result = context._setup_result_proxy()
    
        except BaseException as e:
>           self._handle_dbapi_exception(
                e, str_statement, effective_parameters, cursor, context
            )

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1980: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x11bab6060>
e = MissingGreenlet("greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place?")
statement = 'SELECT th.trans_head.project_id AS th_trans_head_project_id, th.trans_head.content_id AS th_trans_head_content_id, th...ad.updated_at AS th_trans_head_updated_at \nFROM th.trans_head \nWHERE %(param_1)s::VARCHAR = th.trans_head.content_id'
parameters = {'param_1': '110199d4-1732-4b66-826e-cf7dbbe68391'}
cursor = <sqlalchemy.dialects.postgresql.psycopg.AsyncAdapt_psycopg_cursor object at 0x11bafcc00>
context = <sqlalchemy.dialects.postgresql.psycopg.PGExecutionContext_psycopg object at 0x11bae19a0>
is_sub_exec = False

    def _handle_dbapi_exception(
        self,
        e: BaseException,
        statement: Optional[str],
        parameters: Optional[_AnyExecuteParams],
        cursor: Optional[DBAPICursor],
        context: Optional[ExecutionContext],
        is_sub_exec: bool = False,
    ) -> NoReturn:
        exc_info = sys.exc_info()
    
        is_exit_exception = util.is_exit_exception(e)
    
        if not self._is_disconnect:
            self._is_disconnect = (
                isinstance(e, self.dialect.loaded_dbapi.Error)
                and not self.closed
                and self.dialect.is_disconnect(
                    e,
                    self._dbapi_connection if not self.invalidated else None,
                    cursor,
                )
            ) or (is_exit_exception and not self.closed)
    
        invalidate_pool_on_disconnect = not is_exit_exception
    
        ismulti: bool = (
            not is_sub_exec and context.executemany
            if context is not None
            else False
        )
        if self._reentrant_error:
            raise exc.DBAPIError.instance(
                statement,
                parameters,
                e,
                self.dialect.loaded_dbapi.Error,
                hide_parameters=self.engine.hide_parameters,
                dialect=self.dialect,
                ismulti=ismulti,
            ).with_traceback(exc_info[2]) from e
        self._reentrant_error = True
        try:
            # non-DBAPI error - if we already got a context,
            # or there's no string statement, don't wrap it
            should_wrap = isinstance(e, self.dialect.loaded_dbapi.Error) or (
                statement is not None
                and context is None
                and not is_exit_exception
            )
    
            if should_wrap:
                sqlalchemy_exception = exc.DBAPIError.instance(
                    statement,
                    parameters,
                    cast(Exception, e),
                    self.dialect.loaded_dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    connection_invalidated=self._is_disconnect,
                    dialect=self.dialect,
                    ismulti=ismulti,
                )
            else:
                sqlalchemy_exception = None
    
            newraise = None
    
            if (self.dialect._has_events) and not self._execution_options.get(
                "skip_user_error_events", False
            ):
                ctx = ExceptionContextImpl(
                    e,
                    sqlalchemy_exception,
                    self.engine,
                    self.dialect,
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    self._is_disconnect,
                    invalidate_pool_on_disconnect,
                    False,
                )
    
                for fn in self.dialect.dispatch.handle_error:
                    try:
                        # handler returns an exception;
                        # call next handler in a chain
                        per_fn = fn(ctx)
                        if per_fn is not None:
                            ctx.chained_exception = newraise = per_fn
                    except Exception as _raised:
                        # handler raises an exception - stop processing
                        newraise = _raised
                        break
    
                if self._is_disconnect != ctx.is_disconnect:
                    self._is_disconnect = ctx.is_disconnect
                    if sqlalchemy_exception:
                        sqlalchemy_exception.connection_invalidated = (
                            ctx.is_disconnect
                        )
    
                # set up potentially user-defined value for
                # invalidate pool.
                invalidate_pool_on_disconnect = (
                    ctx.invalidate_pool_on_disconnect
                )
    
            if should_wrap and context:
                context.handle_dbapi_exception(e)
    
            if not self._is_disconnect:
                if cursor:
                    self._safe_close_cursor(cursor)
                # "autorollback" was mostly relevant in 1.x series.
                # It's very unlikely to reach here, as the connection
                # does autobegin so when we are here, we are usually
                # in an explicit / semi-explicit transaction.
                # however we have a test which manufactures this
                # scenario in any case using an event handler.
                # test/engine/test_execute.py-> test_actual_autorollback
                if not self.in_transaction():
                    self._rollback_impl()
    
            if newraise:
                raise newraise.with_traceback(exc_info[2]) from e
            elif should_wrap:
                assert sqlalchemy_exception is not None
                raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
            else:
                assert exc_info[1] is not None
>               raise exc_info[1].with_traceback(exc_info[2])

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2352: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x11bab6060>
dialect = <sqlalchemy.dialects.postgresql.psycopg.PGDialectAsync_psycopg object at 0x1127b31d0>
context = <sqlalchemy.dialects.postgresql.psycopg.PGExecutionContext_psycopg object at 0x11bae19a0>
statement = <sqlalchemy.dialects.postgresql.psycopg.PGCompiler_psycopg object at 0x11bae1d90>
parameters = [{'param_1': '110199d4-1732-4b66-826e-cf7dbbe68391'}]

    def _exec_single_context(
        self,
        dialect: Dialect,
        context: ExecutionContext,
        statement: Union[str, Compiled],
        parameters: Optional[_AnyMultiExecuteParams],
    ) -> CursorResult[Any]:
        """continue the _execute_context() method for a single DBAPI
        cursor.execute() or cursor.executemany() call.
    
        """
        if dialect.bind_typing is BindTyping.SETINPUTSIZES:
            generic_setinputsizes = context._prepare_set_input_sizes()
    
            if generic_setinputsizes:
                try:
                    dialect.do_set_input_sizes(
                        context.cursor, generic_setinputsizes, context
                    )
                except BaseException as e:
                    self._handle_dbapi_exception(
                        e, str(statement), parameters, None, context
                    )
    
        cursor, str_statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )
    
        effective_parameters: Optional[_AnyExecuteParams]
    
        if not context.executemany:
            effective_parameters = parameters[0]
        else:
            effective_parameters = parameters
    
        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                str_statement, effective_parameters = fn(
                    self,
                    cursor,
                    str_statement,
                    effective_parameters,
                    context,
                    context.executemany,
                )
    
        if self._echo:
            self._log_info(str_statement)
    
            stats = context._get_cache_stats()
    
            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        effective_parameters,
                        batches=10,
                        ismulti=context.executemany,
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]",
                    stats,
                )
    
        evt_handled: bool = False
        try:
            if context.execute_style is ExecuteStyle.EXECUTEMANY:
                effective_parameters = cast(
                    "_CoreMultiExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor,
                        str_statement,
                        effective_parameters,
                        context,
                    )
            elif not effective_parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, str_statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, str_statement, context
                    )
            else:
                effective_parameters = cast(
                    "_CoreSingleExecuteParams", effective_parameters
                )
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(
                            cursor,
                            str_statement,
                            effective_parameters,
                            context,
                        ):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, str_statement, effective_parameters, context
                    )

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1961: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg.PGDialectAsync_psycopg object at 0x1127b31d0>
cursor = <sqlalchemy.dialects.postgresql.psycopg.AsyncAdapt_psycopg_cursor object at 0x11bafcc00>
statement = 'SELECT th.trans_head.project_id AS th_trans_head_project_id, th.trans_head.content_id AS th_trans_head_content_id, th...ad.updated_at AS th_trans_head_updated_at \nFROM th.trans_head \nWHERE %(param_1)s::VARCHAR = th.trans_head.content_id'
parameters = {'param_1': '110199d4-1732-4b66-826e-cf7dbbe68391'}
context = <sqlalchemy.dialects.postgresql.psycopg.PGExecutionContext_psycopg object at 0x11bae19a0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/sqlalchemy/engine/default.py:944: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.psycopg.AsyncAdapt_psycopg_cursor object at 0x11bafcc00>
query = 'SELECT th.trans_head.project_id AS th_trans_head_project_id, th.trans_head.content_id AS th_trans_head_content_id, th...ad.updated_at AS th_trans_head_updated_at \nFROM th.trans_head \nWHERE %(param_1)s::VARCHAR = th.trans_head.content_id'
params = {'param_1': '110199d4-1732-4b66-826e-cf7dbbe68391'}, kw = {}

    def execute(self, query, params=None, **kw):
>       result = self.await_(self._cursor.execute(query, params, **kw))
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/psycopg.py:594: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

awaitable = <coroutine object AsyncCursor.execute at 0x11ba79900>

    def await_only(awaitable: Awaitable[_T]) -> _T:
        """Awaits an async function in a sync method.
    
        The sync method must be inside a :func:`greenlet_spawn` context.
        :func:`await_only` calls cannot be nested.
    
        :param awaitable: The coroutine to call.
    
        """
        # this is called in the context greenlet while running fn
        current = getcurrent()
        if not getattr(current, "__sqlalchemy_greenlet_provider__", False):
            _safe_cancel_awaitable(awaitable)
    
>           raise exc.MissingGreenlet(
                "greenlet_spawn has not been called; can't call await_only() "
                "here. Was IO attempted in an unexpected place?"
            )
E           sqlalchemy.exc.MissingGreenlet: greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place? (Background on this error at: https://sqlalche.me/e/20/xd2s)

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/sqlalchemy/util/_concurrency_py3k.py:123: MissingGreenlet

During handling of the above exception, another exception occurred:

coordinator = <trans_hub.application.coordinator.Coordinator object at 0x11ba77050>
uow_factory = <dependency_injector.providers.Factory(<class 'trans_hub.infrastructure.uow.SqlAlchemyUnitOfWork'>) at 0x11540d900>

    @pytest.mark.asyncio
    async def test_worker_processes_draft_task_successfully(
        coordinator: Coordinator,  # 用于方便地创建初始请求
        uow_factory: UowFactory,
    ):
        """
        验证 Worker 的 `run_once` 函数能否成功处理一个 'draft' 任务，
        并正确地更新数据库状态（创建新修订、TM等）。
        """
        # 1. 准备：使用 coordinator 创建一个 'draft' 状态的翻译任务
        req_data = create_request_data(
            target_langs=["de"], keys={"id": f"worker-test-{uuid.uuid4().hex[:4]}"}
        )
        await coordinator.request_translation(**req_data)
    
        # 验证初始状态
        async with uow_factory() as uow:
            head_before = await uow.translations.get_head_by_uida(
                project_id=req_data["project_id"],
                namespace=req_data["namespace"],
                keys=req_data["keys"],
                target_lang="de",
                variant_key="-",
            )
            assert head_before is not None
            assert head_before.current_status == TranslationStatus.DRAFT
            assert head_before.current_no == 0
            # 保存 current_rev_id 以避免 DetachedInstanceError
            head_before_rev_id = head_before.current_rev_id
    
        # 2. 准备 Worker 的依赖
        fake_engine = FakeTranslationEngine(config=FakeEngineConfig())
        # stream_producer 暂时为 None，因为事件现在走 Outbox
        processor = TranslationProcessor(stream_producer=None, event_stream_name="")
    
        # 3. 执行：调用 worker 的核心处理逻辑
>       await run_once(
            uow_factory=uow_factory,
            processor=processor,
            active_engine=fake_engine,
            batch_size=10,
        )

tests/integration/workers/test_worker_run_once.py:56: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

uow_factory = <dependency_injector.providers.Factory(<class 'trans_hub.infrastructure.uow.SqlAlchemyUnitOfWork'>) at 0x11540d900>
processor = <trans_hub.application.processors.TranslationProcessor object at 0x11bab6390>
active_engine = <tests.helpers.tools.fakes.FakeTranslationEngine object at 0x11bab76b0>
batch_size = 10

    async def run_once(
        uow_factory: UowFactory,
        processor: TranslationProcessor,
        active_engine: BaseTranslationEngine[Any],
        batch_size: int,
    ) -> None:
        """
        执行一轮 Worker 的核心处理逻辑。
        它现在使用 UoW 来确保拉取和处理任务的原子性。
        """
        tasks_processed = 0
        try:
            # Worker 的核心逻辑现在在一个独立的 UoW 中运行
            async with uow_factory() as uow:
                # 使用流式处理，但在同一个 session 中
                # 注意：这里的 stream_drafts 内部使用了 FOR UPDATE SKIP LOCKED
                # 它将在事务提交前一直持有行锁
                async for batch in uow.translations.stream_drafts(batch_size):
                    if not batch:
                        continue
    
                    logger.info("获取到新一批翻译任务，正在处理...", count=len(batch))
    
                    # 处理器现在也接收 UoW 实例，以便在同一个事务中执行更新
                    await processor.process_batch(uow, batch, active_engine)
                    tasks_processed += len(batch)
    
            if tasks_processed > 0:
                logger.info("本轮任务处理完成。", total_processed=tasks_processed)
            else:
                logger.debug("本轮未发现需要处理的任务。")
    
        except Exception as e:
>           logger.error("处理任务批次时发生未知错误。", error=e, exc_info=True)

src/trans_hub/workers/_translation_worker.py:54: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <BoundLoggerFilteringAtNotset(context={}, processors=[<function merge_contextvars at 0x1134ea340>, <function add_log_l...e0>, <structlog.processors.TimeStamper object at 0x113cf3980>, <structlog.dev.ConsoleRenderer object at 0x114007a70>])>
event = '处理任务批次时发生未知错误。', args = ()
kw = {'error': MissingGreenlet("greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place?"), 'exc_info': True}

    def meth(self: Any, event: str, *args: Any, **kw: Any) -> Any:
        if not args:
>           return self._proxy_to_logger(name, event, **kw)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/structlog/_native.py:134: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <BoundLoggerFilteringAtNotset(context={}, processors=[<function merge_contextvars at 0x1134ea340>, <function add_log_l...e0>, <structlog.processors.TimeStamper object at 0x113cf3980>, <structlog.dev.ConsoleRenderer object at 0x114007a70>])>
method_name = 'error', event = '处理任务批次时发生未知错误。'
event_kw = {'error': MissingGreenlet("greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place?"), 'exc_info': True}

    def _proxy_to_logger(
        self, method_name: str, event: str | None = None, **event_kw: Any
    ) -> Any:
        """
        Run processor chain on event & call *method_name* on wrapped logger.
    
        DRY convenience method that runs :func:`_process_event`, takes care of
        handling :exc:`structlog.DropEvent`, and finally calls *method_name* on
        :attr:`_logger` with the result.
    
        Args:
            method_name:
                The name of the method that's going to get called.  Technically
                it should be identical to the method the user called because it
                also get passed into processors.
    
            event:
                The event -- usually the first positional argument to a logger.
    
            event_kw:
                Additional event keywords.  For example if someone calls
                ``log.info("foo", bar=42)``, *event* would to be ``"foo"`` and
                *event_kw* ``{"bar": 42}``.
    
        .. note::
            Despite underscore available to custom wrapper classes.
    
            See also `custom-wrappers`.
        """
        try:
>           args, kw = self._process_event(method_name, event, event_kw)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/structlog/_base.py:214: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <BoundLoggerFilteringAtNotset(context={}, processors=[<function merge_contextvars at 0x1134ea340>, <function add_log_l...e0>, <structlog.processors.TimeStamper object at 0x113cf3980>, <structlog.dev.ConsoleRenderer object at 0x114007a70>])>
method_name = 'error', event = '处理任务批次时发生未知错误。'
event_kw = {'error': MissingGreenlet("greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place?"), 'exc_info': True}

    def _process_event(
        self, method_name: str, event: str | None, event_kw: dict[str, Any]
    ) -> tuple[Sequence[Any], Mapping[str, Any]]:
        """
        Combines creates an ``event_dict`` and runs the chain.
    
        Call it to combine your *event* and *context* into an event_dict and
        process using the processor chain.
    
        Args:
            method_name:
                The name of the logger method.  Is passed into the processors.
    
            event:
                The event -- usually the first positional argument to a logger.
    
            event_kw:
                Additional event keywords.  For example if someone calls
                ``log.info("foo", bar=42)``, *event* would to be ``"foo"`` and
                *event_kw* ``{"bar": 42}``.
    
        Raises:
            structlog.DropEvent: if log entry should be dropped.
    
            ValueError:
                if the final processor doesn't return a str, bytes, bytearray,
                tuple, or a dict.
    
        Returns:
             `tuple` of ``(*args, **kw)``
    
        .. note::
            Despite underscore available to custom wrapper classes.
    
            See also `custom-wrappers`.
    
        .. versionchanged:: 14.0.0
            Allow final processor to return a `dict`.
        .. versionchanged:: 20.2.0
            Allow final processor to return `bytes`.
        .. versionchanged:: 21.2.0
            Allow final processor to return a `bytearray`.
        """
        # We're typing it as Any, because processors can return more than an
        # EventDict.
        event_dict: Any = self._context.copy()
        event_dict.update(**event_kw)
    
        if event is not None:
            event_dict["event"] = event
        for proc in self._processors:
>           event_dict = proc(self._logger, method_name, event_dict)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/structlog/_base.py:165: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <structlog.dev.ConsoleRenderer object at 0x114007a70>
logger = <PrintLogger(file=<_io.TextIOWrapper name="<_io.FileIO name=6 mode='rb+' closefd=True>" mode='r+' encoding='utf-8'>)>
name = 'error'
event_dict = {'error': MissingGreenlet("greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place?")}

    def __call__(
        self, logger: WrappedLogger, name: str, event_dict: EventDict
    ) -> str:
        stack = event_dict.pop("stack", None)
        exc = event_dict.pop("exception", None)
        exc_info = event_dict.pop("exc_info", None)
    
        kvs = [
            col.formatter(col.key, val)
            for col in self._columns
            if (val := event_dict.pop(col.key, _NOTHING)) is not _NOTHING
        ] + [
            self._default_column_formatter(key, event_dict[key])
            for key in (sorted(event_dict) if self._sort_keys else event_dict)
        ]
    
        sio = StringIO()
        sio.write((" ".join(kv for kv in kvs if kv)).rstrip(" "))
    
        if stack is not None:
            sio.write("\n" + stack)
            if exc_info or exc is not None:
                sio.write("\n\n" + "=" * 79 + "\n")
    
        if exc_info:
            exc_info = _figure_out_exc_info(exc_info)
    
            if exc_info != (None, None, None):
>               self._exception_formatter(sio, exc_info)

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/structlog/dev.py:738: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = RichTracebackFormatter(color_system='truecolor', show_locals=True, max_frames=100, theme=None, word_wrap=False, extra_...uides=True, locals_max_length=10, locals_max_string=80, locals_hide_dunder=True, locals_hide_sunder=False, suppress=())
sio = <_io.StringIO object at 0x11b9aa5c0>
exc_info = (<class 'sqlalchemy.exc.MissingGreenlet'>, MissingGreenlet("greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place?"), <traceback object at 0x11baff280>)

    def __call__(self, sio: TextIO, exc_info: ExcInfo) -> None:
        if self.width == -1:
            self.width, _ = shutil.get_terminal_size((80, 0))
    
        sio.write("\n")
    
        Console(
            file=sio, color_system=self.color_system, width=self.width
        ).print(
>           Traceback.from_exception(
                *exc_info,
                show_locals=self.show_locals,
                max_frames=self.max_frames,
                theme=self.theme,
                word_wrap=self.word_wrap,
                extra_lines=self.extra_lines,
                width=self.width,
                indent_guides=self.indent_guides,
                locals_max_length=self.locals_max_length,
                locals_max_string=self.locals_max_string,
                locals_hide_dunder=self.locals_hide_dunder,
                locals_hide_sunder=self.locals_hide_sunder,
                suppress=self.suppress,
            )
        )

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/structlog/dev.py:382: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'rich.traceback.Traceback'>
exc_type = <class 'sqlalchemy.exc.MissingGreenlet'>
exc_value = MissingGreenlet("greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place?")
traceback = <traceback object at 0x11baff280>

    @classmethod
    def from_exception(
        cls,
        exc_type: Type[Any],
        exc_value: BaseException,
        traceback: Optional[TracebackType],
        *,
        width: Optional[int] = 100,
        code_width: Optional[int] = 88,
        extra_lines: int = 3,
        theme: Optional[str] = None,
        word_wrap: bool = False,
        show_locals: bool = False,
        locals_max_length: int = LOCALS_MAX_LENGTH,
        locals_max_string: int = LOCALS_MAX_STRING,
        locals_hide_dunder: bool = True,
        locals_hide_sunder: bool = False,
        indent_guides: bool = True,
        suppress: Iterable[Union[str, ModuleType]] = (),
        max_frames: int = 100,
    ) -> "Traceback":
        """Create a traceback from exception info
    
        Args:
            exc_type (Type[BaseException]): Exception type.
            exc_value (BaseException): Exception value.
            traceback (TracebackType): Python Traceback object.
            width (Optional[int], optional): Number of characters used to traceback. Defaults to 100.
            code_width (Optional[int], optional): Number of code characters used to traceback. Defaults to 88.
            extra_lines (int, optional): Additional lines of code to render. Defaults to 3.
            theme (str, optional): Override pygments theme used in traceback.
            word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.
            show_locals (bool, optional): Enable display of local variables. Defaults to False.
            indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.
            locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
                Defaults to 10.
            locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.
            locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.
            locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.
            suppress (Iterable[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.
            max_frames (int): Maximum number of frames to show in a traceback, 0 for no maximum. Defaults to 100.
    
        Returns:
            Traceback: A Traceback instance that may be printed.
        """
>       rich_traceback = cls.extract(
            exc_type,
            exc_value,
            traceback,
            show_locals=show_locals,
            locals_max_length=locals_max_length,
            locals_max_string=locals_max_string,
            locals_hide_dunder=locals_hide_dunder,
            locals_hide_sunder=locals_hide_sunder,
        )

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/rich/traceback.py:384: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'rich.traceback.Traceback'>
exc_type = <class 'sqlalchemy.exc.MissingGreenlet'>
exc_value = MissingGreenlet("greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place?")
traceback = <traceback object at 0x11baff280>

    @classmethod
    def extract(
        cls,
        exc_type: Type[BaseException],
        exc_value: BaseException,
        traceback: Optional[TracebackType],
        *,
        show_locals: bool = False,
        locals_max_length: int = LOCALS_MAX_LENGTH,
        locals_max_string: int = LOCALS_MAX_STRING,
        locals_hide_dunder: bool = True,
        locals_hide_sunder: bool = False,
        _visited_exceptions: Optional[Set[BaseException]] = None,
    ) -> Trace:
        """Extract traceback information.
    
        Args:
            exc_type (Type[BaseException]): Exception type.
            exc_value (BaseException): Exception value.
            traceback (TracebackType): Python Traceback object.
            show_locals (bool, optional): Enable display of local variables. Defaults to False.
            locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
                Defaults to 10.
            locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.
            locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.
            locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.
    
        Returns:
            Trace: A Trace instance which you can use to construct a `Traceback`.
        """
    
        stacks: List[Stack] = []
        is_cause = False
    
        from rich import _IMPORT_CWD
    
        notes: List[str] = getattr(exc_value, "__notes__", None) or []
    
        grouped_exceptions: Set[BaseException] = (
            set() if _visited_exceptions is None else _visited_exceptions
        )
    
        def safe_str(_object: Any) -> str:
            """Don't allow exceptions from __str__ to propagate."""
            try:
                return str(_object)
            except Exception:
                return "<exception str() failed>"
    
        while True:
            stack = Stack(
                exc_type=safe_str(exc_type.__name__),
                exc_value=safe_str(exc_value),
                is_cause=is_cause,
                notes=notes,
            )
    
            if sys.version_info >= (3, 11):
                if isinstance(exc_value, (BaseExceptionGroup, ExceptionGroup)):
                    stack.is_group = True
                    for exception in exc_value.exceptions:
                        if exception in grouped_exceptions:
                            continue
                        grouped_exceptions.add(exception)
                        stack.exceptions.append(
                            Traceback.extract(
                                type(exception),
                                exception,
                                exception.__traceback__,
                                show_locals=show_locals,
                                locals_max_length=locals_max_length,
                                locals_hide_dunder=locals_hide_dunder,
                                locals_hide_sunder=locals_hide_sunder,
                                _visited_exceptions=grouped_exceptions,
                            )
                        )
    
            if isinstance(exc_value, SyntaxError):
                stack.syntax_error = _SyntaxError(
                    offset=exc_value.offset or 0,
                    filename=exc_value.filename or "?",
                    lineno=exc_value.lineno or 0,
                    line=exc_value.text or "",
                    msg=exc_value.msg,
                    notes=notes,
                )
    
            stacks.append(stack)
            append = stack.frames.append
    
            def get_locals(
                iter_locals: Iterable[Tuple[str, object]],
            ) -> Iterable[Tuple[str, object]]:
                """Extract locals from an iterator of key pairs."""
                if not (locals_hide_dunder or locals_hide_sunder):
                    yield from iter_locals
                    return
                for key, value in iter_locals:
                    if locals_hide_dunder and key.startswith("__"):
                        continue
                    if locals_hide_sunder and key.startswith("_"):
                        continue
                    yield key, value
    
            for frame_summary, line_no in walk_tb(traceback):
                filename = frame_summary.f_code.co_filename
    
                last_instruction: Optional[Tuple[Tuple[int, int], Tuple[int, int]]]
                last_instruction = None
                if sys.version_info >= (3, 11):
                    instruction_index = frame_summary.f_lasti // 2
                    instruction_position = next(
                        islice(
                            frame_summary.f_code.co_positions(),
                            instruction_index,
                            instruction_index + 1,
                        )
                    )
                    (
                        start_line,
                        end_line,
                        start_column,
                        end_column,
                    ) = instruction_position
                    if (
                        start_line is not None
                        and end_line is not None
                        and start_column is not None
                        and end_column is not None
                    ):
                        last_instruction = (
                            (start_line, start_column),
                            (end_line, end_column),
                        )
    
                if filename and not filename.startswith("<"):
                    if not os.path.isabs(filename):
                        filename = os.path.join(_IMPORT_CWD, filename)
                if frame_summary.f_locals.get("_rich_traceback_omit", False):
                    continue
    
                frame = Frame(
                    filename=filename or "?",
                    lineno=line_no,
                    name=frame_summary.f_code.co_name,
                    locals=(
                        {
>                           key: pretty.traverse(
                                value,
                                max_length=locals_max_length,
                                max_string=locals_max_string,
                            )
                            for key, value in get_locals(frame_summary.f_locals.items())
                            if not (inspect.isfunction(value) or inspect.isclass(value))
                        }
                        if show_locals
                        else None
                    ),
                    last_instruction=last_instruction,
                )

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/rich/traceback.py:559: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

_object = <[DetachedInstanceError('Instance <ThTransHead at 0x11bae06e0> is not bound to a Session; attribute refresh operation cannot proceed') raised in repr()] ThTransHead object at 0x11bae06e0>
max_length = 10, max_string = 80, max_depth = None

    def traverse(
        _object: Any,
        max_length: Optional[int] = None,
        max_string: Optional[int] = None,
        max_depth: Optional[int] = None,
    ) -> Node:
        """Traverse object and generate a tree.
    
        Args:
            _object (Any): Object to be traversed.
            max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.
                Defaults to None.
            max_string (int, optional): Maximum length of string before truncating, or None to disable truncating.
                Defaults to None.
            max_depth (int, optional): Maximum depth of data structures, or None for no maximum.
                Defaults to None.
    
        Returns:
            Node: The root of a tree structure which can be used to render a pretty repr.
        """
    
        def to_repr(obj: Any) -> str:
            """Get repr string for an object, but catch errors."""
            if (
                max_string is not None
                and _safe_isinstance(obj, (bytes, str))
                and len(obj) > max_string
            ):
                truncated = len(obj) - max_string
                obj_repr = f"{obj[:max_string]!r}+{truncated}"
            else:
                try:
                    obj_repr = repr(obj)
                except Exception as error:
                    obj_repr = f"<repr-error {str(error)!r}>"
            return obj_repr
    
        visited_ids: Set[int] = set()
        push_visited = visited_ids.add
        pop_visited = visited_ids.remove
    
        def _traverse(obj: Any, root: bool = False, depth: int = 0) -> Node:
            """Walk the object depth first."""
    
            obj_id = id(obj)
            if obj_id in visited_ids:
                # Recursion detected
                return Node(value_repr="...")
    
            obj_type = type(obj)
            children: List[Node]
            reached_max_depth = max_depth is not None and depth >= max_depth
    
            def iter_rich_args(rich_args: Any) -> Iterable[Union[Any, Tuple[str, Any]]]:
                for arg in rich_args:
                    if _safe_isinstance(arg, tuple):
                        if len(arg) == 3:
                            key, child, default = arg
                            if default == child:
                                continue
                            yield key, child
                        elif len(arg) == 2:
                            key, child = arg
                            yield key, child
                        elif len(arg) == 1:
                            yield arg[0]
                    else:
                        yield arg
    
            try:
                fake_attributes = hasattr(
                    obj, "awehoi234_wdfjwljet234_234wdfoijsdfmmnxpi492"
                )
            except Exception:
                fake_attributes = False
    
            rich_repr_result: Optional[RichReprResult] = None
            if not fake_attributes:
                try:
                    if hasattr(obj, "__rich_repr__") and not isclass(obj):
                        rich_repr_result = obj.__rich_repr__()
                except Exception:
                    pass
    
            if rich_repr_result is not None:
                push_visited(obj_id)
                angular = getattr(obj.__rich_repr__, "angular", False)
                args = list(iter_rich_args(rich_repr_result))
                class_name = obj.__class__.__name__
    
                if args:
                    children = []
                    append = children.append
    
                    if reached_max_depth:
                        if angular:
                            node = Node(value_repr=f"<{class_name}...>")
                        else:
                            node = Node(value_repr=f"{class_name}(...)")
                    else:
                        if angular:
                            node = Node(
                                open_brace=f"<{class_name} ",
                                close_brace=">",
                                children=children,
                                last=root,
                                separator=" ",
                            )
                        else:
                            node = Node(
                                open_brace=f"{class_name}(",
                                close_brace=")",
                                children=children,
                                last=root,
                            )
                        for last, arg in loop_last(args):
                            if _safe_isinstance(arg, tuple):
                                key, child = arg
                                child_node = _traverse(child, depth=depth + 1)
                                child_node.last = last
                                child_node.key_repr = key
                                child_node.key_separator = "="
                                append(child_node)
                            else:
                                child_node = _traverse(arg, depth=depth + 1)
                                child_node.last = last
                                append(child_node)
                else:
                    node = Node(
                        value_repr=f"<{class_name}>" if angular else f"{class_name}()",
                        children=[],
                        last=root,
                    )
                pop_visited(obj_id)
            elif _is_attr_object(obj) and not fake_attributes:
                push_visited(obj_id)
                children = []
                append = children.append
    
                attr_fields = _get_attr_fields(obj)
                if attr_fields:
                    if reached_max_depth:
                        node = Node(value_repr=f"{obj.__class__.__name__}(...)")
                    else:
                        node = Node(
                            open_brace=f"{obj.__class__.__name__}(",
                            close_brace=")",
                            children=children,
                            last=root,
                        )
    
                        def iter_attrs() -> (
                            Iterable[Tuple[str, Any, Optional[Callable[[Any], str]]]]
                        ):
                            """Iterate over attr fields and values."""
                            for attr in attr_fields:
                                if attr.repr:
                                    try:
                                        value = getattr(obj, attr.name)
                                    except Exception as error:
                                        # Can happen, albeit rarely
                                        yield (attr.name, error, None)
                                    else:
                                        yield (
                                            attr.name,
                                            value,
                                            attr.repr if callable(attr.repr) else None,
                                        )
    
                        for last, (name, value, repr_callable) in loop_last(iter_attrs()):
                            if repr_callable:
                                child_node = Node(value_repr=str(repr_callable(value)))
                            else:
                                child_node = _traverse(value, depth=depth + 1)
                            child_node.last = last
                            child_node.key_repr = name
                            child_node.key_separator = "="
                            append(child_node)
                else:
                    node = Node(
                        value_repr=f"{obj.__class__.__name__}()", children=[], last=root
                    )
                pop_visited(obj_id)
            elif (
                is_dataclass(obj)
                and not _safe_isinstance(obj, type)
                and not fake_attributes
                and _is_dataclass_repr(obj)
            ):
                push_visited(obj_id)
                children = []
                append = children.append
                if reached_max_depth:
                    node = Node(value_repr=f"{obj.__class__.__name__}(...)")
                else:
                    node = Node(
                        open_brace=f"{obj.__class__.__name__}(",
                        close_brace=")",
                        children=children,
                        last=root,
                        empty=f"{obj.__class__.__name__}()",
                    )
    
                    for last, field in loop_last(
                        field
                        for field in fields(obj)
                        if field.repr and hasattr(obj, field.name)
                    ):
                        child_node = _traverse(getattr(obj, field.name), depth=depth + 1)
                        child_node.key_repr = field.name
                        child_node.last = last
                        child_node.key_separator = "="
                        append(child_node)
    
                pop_visited(obj_id)
            elif _is_namedtuple(obj) and _has_default_namedtuple_repr(obj):
                push_visited(obj_id)
                class_name = obj.__class__.__name__
                if reached_max_depth:
                    # If we've reached the max depth, we still show the class name, but not its contents
                    node = Node(
                        value_repr=f"{class_name}(...)",
                    )
                else:
                    children = []
                    append = children.append
                    node = Node(
                        open_brace=f"{class_name}(",
                        close_brace=")",
                        children=children,
                        empty=f"{class_name}()",
                    )
                    for last, (key, value) in loop_last(obj._asdict().items()):
                        child_node = _traverse(value, depth=depth + 1)
                        child_node.key_repr = key
                        child_node.last = last
                        child_node.key_separator = "="
                        append(child_node)
                pop_visited(obj_id)
            elif _safe_isinstance(obj, _CONTAINERS):
                for container_type in _CONTAINERS:
                    if _safe_isinstance(obj, container_type):
                        obj_type = container_type
                        break
    
                push_visited(obj_id)
    
                open_brace, close_brace, empty = _BRACES[obj_type](obj)
    
                if reached_max_depth:
                    node = Node(value_repr=f"{open_brace}...{close_brace}")
                elif obj_type.__repr__ != type(obj).__repr__:
                    node = Node(value_repr=to_repr(obj), last=root)
                elif obj:
                    children = []
                    node = Node(
                        open_brace=open_brace,
                        close_brace=close_brace,
                        children=children,
                        last=root,
                    )
                    append = children.append
                    num_items = len(obj)
                    last_item_index = num_items - 1
    
                    if _safe_isinstance(obj, _MAPPING_CONTAINERS):
                        iter_items = iter(obj.items())
                        if max_length is not None:
                            iter_items = islice(iter_items, max_length)
                        for index, (key, child) in enumerate(iter_items):
                            child_node = _traverse(child, depth=depth + 1)
                            child_node.key_repr = to_repr(key)
                            child_node.last = index == last_item_index
                            append(child_node)
                    else:
                        iter_values = iter(obj)
                        if max_length is not None:
                            iter_values = islice(iter_values, max_length)
                        for index, child in enumerate(iter_values):
                            child_node = _traverse(child, depth=depth + 1)
                            child_node.last = index == last_item_index
                            append(child_node)
                    if max_length is not None and num_items > max_length:
                        append(Node(value_repr=f"... +{num_items - max_length}", last=True))
                else:
                    node = Node(empty=empty, children=[], last=root)
    
                pop_visited(obj_id)
            else:
                node = Node(value_repr=to_repr(obj), last=root)
            node.is_tuple = type(obj) == tuple
            node.is_namedtuple = _is_namedtuple(obj)
            return node
    
>       node = _traverse(_object, root=True)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/rich/pretty.py:874: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

obj = <[DetachedInstanceError('Instance <ThTransHead at 0x11bae06e0> is not bound to a Session; attribute refresh operation cannot proceed') raised in repr()] ThTransHead object at 0x11bae06e0>
root = True, depth = 0

    def _traverse(obj: Any, root: bool = False, depth: int = 0) -> Node:
        """Walk the object depth first."""
    
        obj_id = id(obj)
        if obj_id in visited_ids:
            # Recursion detected
            return Node(value_repr="...")
    
        obj_type = type(obj)
        children: List[Node]
        reached_max_depth = max_depth is not None and depth >= max_depth
    
        def iter_rich_args(rich_args: Any) -> Iterable[Union[Any, Tuple[str, Any]]]:
            for arg in rich_args:
                if _safe_isinstance(arg, tuple):
                    if len(arg) == 3:
                        key, child, default = arg
                        if default == child:
                            continue
                        yield key, child
                    elif len(arg) == 2:
                        key, child = arg
                        yield key, child
                    elif len(arg) == 1:
                        yield arg[0]
                else:
                    yield arg
    
        try:
            fake_attributes = hasattr(
                obj, "awehoi234_wdfjwljet234_234wdfoijsdfmmnxpi492"
            )
        except Exception:
            fake_attributes = False
    
        rich_repr_result: Optional[RichReprResult] = None
        if not fake_attributes:
            try:
                if hasattr(obj, "__rich_repr__") and not isclass(obj):
                    rich_repr_result = obj.__rich_repr__()
            except Exception:
                pass
    
        if rich_repr_result is not None:
            push_visited(obj_id)
            angular = getattr(obj.__rich_repr__, "angular", False)
            args = list(iter_rich_args(rich_repr_result))
            class_name = obj.__class__.__name__
    
            if args:
                children = []
                append = children.append
    
                if reached_max_depth:
                    if angular:
                        node = Node(value_repr=f"<{class_name}...>")
                    else:
                        node = Node(value_repr=f"{class_name}(...)")
                else:
                    if angular:
                        node = Node(
                            open_brace=f"<{class_name} ",
                            close_brace=">",
                            children=children,
                            last=root,
                            separator=" ",
                        )
                    else:
                        node = Node(
                            open_brace=f"{class_name}(",
                            close_brace=")",
                            children=children,
                            last=root,
                        )
                    for last, arg in loop_last(args):
                        if _safe_isinstance(arg, tuple):
                            key, child = arg
                            child_node = _traverse(child, depth=depth + 1)
                            child_node.last = last
                            child_node.key_repr = key
                            child_node.key_separator = "="
                            append(child_node)
                        else:
                            child_node = _traverse(arg, depth=depth + 1)
                            child_node.last = last
                            append(child_node)
            else:
                node = Node(
                    value_repr=f"<{class_name}>" if angular else f"{class_name}()",
                    children=[],
                    last=root,
                )
            pop_visited(obj_id)
        elif _is_attr_object(obj) and not fake_attributes:
            push_visited(obj_id)
            children = []
            append = children.append
    
            attr_fields = _get_attr_fields(obj)
            if attr_fields:
                if reached_max_depth:
                    node = Node(value_repr=f"{obj.__class__.__name__}(...)")
                else:
                    node = Node(
                        open_brace=f"{obj.__class__.__name__}(",
                        close_brace=")",
                        children=children,
                        last=root,
                    )
    
                    def iter_attrs() -> (
                        Iterable[Tuple[str, Any, Optional[Callable[[Any], str]]]]
                    ):
                        """Iterate over attr fields and values."""
                        for attr in attr_fields:
                            if attr.repr:
                                try:
                                    value = getattr(obj, attr.name)
                                except Exception as error:
                                    # Can happen, albeit rarely
                                    yield (attr.name, error, None)
                                else:
                                    yield (
                                        attr.name,
                                        value,
                                        attr.repr if callable(attr.repr) else None,
                                    )
    
                    for last, (name, value, repr_callable) in loop_last(iter_attrs()):
                        if repr_callable:
                            child_node = Node(value_repr=str(repr_callable(value)))
                        else:
                            child_node = _traverse(value, depth=depth + 1)
                        child_node.last = last
                        child_node.key_repr = name
                        child_node.key_separator = "="
                        append(child_node)
            else:
                node = Node(
                    value_repr=f"{obj.__class__.__name__}()", children=[], last=root
                )
            pop_visited(obj_id)
        elif (
            is_dataclass(obj)
            and not _safe_isinstance(obj, type)
            and not fake_attributes
            and _is_dataclass_repr(obj)
        ):
            push_visited(obj_id)
            children = []
            append = children.append
            if reached_max_depth:
                node = Node(value_repr=f"{obj.__class__.__name__}(...)")
            else:
                node = Node(
                    open_brace=f"{obj.__class__.__name__}(",
                    close_brace=")",
                    children=children,
                    last=root,
                    empty=f"{obj.__class__.__name__}()",
                )
    
>               for last, field in loop_last(
                    field
                    for field in fields(obj)
                    if field.repr and hasattr(obj, field.name)
                ):

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/rich/pretty.py:783: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

values = <generator object traverse.<locals>._traverse.<locals>.<genexpr> at 0x11baf6f80>

    def loop_last(values: Iterable[T]) -> Iterable[Tuple[bool, T]]:
        """Iterate and generate a tuple with a flag for last value."""
        iter_values = iter(values)
        try:
>           previous_value = next(iter_values)
                             ^^^^^^^^^^^^^^^^^

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/rich/_loop.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <tuple_iterator object at 0x11bb51660>

    for last, field in loop_last(
        field
        for field in fields(obj)
>       if field.repr and hasattr(obj, field.name)
                          ^^^^^^^^^^^^^^^^^^^^^^^^
    ):

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/rich/pretty.py:786: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.attributes.InstrumentedAttribute object at 0x1140c9c60>
instance = <[DetachedInstanceError('Instance <ThTransHead at 0x11bae06e0> is not bound to a Session; attribute refresh operation cannot proceed') raised in repr()] ThTransHead object at 0x11bae06e0>
owner = <class 'trans_hub.infrastructure.db._schema.ThTransHead'>

    def __get__(
        self, instance: Optional[object], owner: Any
    ) -> Union[InstrumentedAttribute[_T_co], _T_co]:
        if instance is None:
            return self
    
        dict_ = instance_dict(instance)
        if self.impl.supports_population and self.key in dict_:
            return dict_[self.key]  # type: ignore[no-any-return]
        else:
            try:
                state = instance_state(instance)
            except AttributeError as err:
                raise orm_exc.UnmappedInstanceError(instance) from err
>           return self.impl.get(state, dict_)  # type: ignore[no-any-return]
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/sqlalchemy/orm/attributes.py:569: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.attributes.ScalarAttributeImpl object at 0x11b9d5760>
state = <sqlalchemy.orm.state.InstanceState object at 0x11bae4350>
dict_ = {'_sa_instance_state': <sqlalchemy.orm.state.InstanceState object at 0x11bae4350>}
passive = symbol('PASSIVE_OFF')

    def get(
        self,
        state: InstanceState[Any],
        dict_: _InstanceDict,
        passive: PassiveFlag = PASSIVE_OFF,
    ) -> Any:
        """Retrieve a value from the given object.
        If a callable is assembled on this object's attribute, and
        passive is False, the callable will be executed and the
        resulting value will be set as the new value for this attribute.
        """
        if self.key in dict_:
            return dict_[self.key]
        else:
            # if history present, don't load
            key = self.key
            if (
                key not in state.committed_state
                or state.committed_state[key] is NO_VALUE
            ):
                if not passive & CALLABLES_OK:
                    return PASSIVE_NO_RESULT
    
>               value = self._fire_loader_callables(state, key, passive)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/sqlalchemy/orm/attributes.py:1096: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.attributes.ScalarAttributeImpl object at 0x11b9d5760>
state = <sqlalchemy.orm.state.InstanceState object at 0x11bae4350>
key = 'project_id', passive = symbol('PASSIVE_OFF')

    def _fire_loader_callables(
        self, state: InstanceState[Any], key: str, passive: PassiveFlag
    ) -> Any:
        if (
            self.accepts_scalar_loader
            and self.load_on_unexpire
            and key in state.expired_attributes
        ):
>           return state._load_expired(state, passive)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/sqlalchemy/orm/attributes.py:1126: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.orm.state.InstanceState object at 0x11bae4350>
state = <sqlalchemy.orm.state.InstanceState object at 0x11bae4350>
passive = symbol('PASSIVE_OFF')

    def _load_expired(
        self, state: InstanceState[_O], passive: PassiveFlag
    ) -> LoaderCallableStatus:
        """__call__ allows the InstanceState to act as a deferred
        callable for loading expired attributes, which is also
        serializable (picklable).
    
        """
    
        if not passive & SQL_OK:
            return PASSIVE_NO_RESULT
    
        toload = self.expired_attributes.intersection(self.unmodified)
        toload = toload.difference(
            attr
            for attr in toload
            if not self.manager[attr].impl.load_on_unexpire
        )
    
>       self.manager.expired_attribute_loader(self, toload, passive)

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/sqlalchemy/orm/state.py:803: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

mapper = <Mapper at 0x113b59310; ThTransHead>
state = <sqlalchemy.orm.state.InstanceState object at 0x11bae4350>
attribute_names = {'content', 'content_id', 'current_no', 'current_rev_id', 'current_status', 'id', ...}
passive = symbol('PASSIVE_OFF')

    def load_scalar_attributes(mapper, state, attribute_names, passive):
        """initiate a column-based attribute refresh operation."""
    
        # assert mapper is _state_mapper(state)
        session = state.session
        if not session:
>           raise orm_exc.DetachedInstanceError(
                "Instance %s is not bound to a Session; "
                "attribute refresh operation cannot proceed" % (state_str(state))
            )
E           sqlalchemy.orm.exc.DetachedInstanceError: Instance <ThTransHead at 0x11bae06e0> is not bound to a Session; attribute refresh operation cannot proceed (Background on this error at: https://sqlalche.me/e/20/bhk3)

/Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/sqlalchemy/orm/loading.py:1603: DetachedInstanceError
----------------------------- Captured stdout call -----------------------------
2025-08-24 20:17:00 [info     ] 获取到新一批翻译任务，正在处理...             count=2
=============================== warnings summary ===============================
tests/integration/workers/test_worker_run_once.py:17
  /Users/saken/Library/CloudStorage/坚果云-saken.w@163.com/工作同步/Code/Trans-Hub/packages/server/tests/integration/workers/test_worker_run_once.py:17: PytestUnknownMarkWarning: Unknown pytest.mark.db - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    pytestmark = [pytest.mark.db, pytest.mark.integration, pytest.mark.slow]

tests/integration/workers/test_worker_run_once.py:17
  /Users/saken/Library/CloudStorage/坚果云-saken.w@163.com/工作同步/Code/Trans-Hub/packages/server/tests/integration/workers/test_worker_run_once.py:17: PytestUnknownMarkWarning: Unknown pytest.mark.integration - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    pytestmark = [pytest.mark.db, pytest.mark.integration, pytest.mark.slow]

tests/integration/workers/test_worker_run_once.py:17
  /Users/saken/Library/CloudStorage/坚果云-saken.w@163.com/工作同步/Code/Trans-Hub/packages/server/tests/integration/workers/test_worker_run_once.py:17: PytestUnknownMarkWarning: Unknown pytest.mark.slow - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    pytestmark = [pytest.mark.db, pytest.mark.integration, pytest.mark.slow]

tests/integration/application/test_app_flow.py:13
  /Users/saken/Library/CloudStorage/坚果云-saken.w@163.com/工作同步/Code/Trans-Hub/packages/server/tests/integration/application/test_app_flow.py:13: PytestUnknownMarkWarning: Unknown pytest.mark.db - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    pytestmark = [pytest.mark.db, pytest.mark.integration]

tests/integration/application/test_app_flow.py:13
  /Users/saken/Library/CloudStorage/坚果云-saken.w@163.com/工作同步/Code/Trans-Hub/packages/server/tests/integration/application/test_app_flow.py:13: PytestUnknownMarkWarning: Unknown pytest.mark.integration - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    pytestmark = [pytest.mark.db, pytest.mark.integration]

tests/integration/application/test_app_flow.py::test_full_request_publish_get_flow
  /Users/saken/Library/Caches/pypoetry/virtualenvs/trans-hub-server-sJagBkCR-py3.12/lib/python3.12/site-packages/alembic/config.py:560: DeprecationWarning: No path_separator found in configuration; falling back to legacy splitting on spaces/commas for version_locations.  Consider adding path_separator=os to Alembic config.
    util.warn_deprecated(

tests/integration/application/test_app_flow.py::test_full_request_publish_get_flow
  /Users/saken/Library/CloudStorage/坚果云-saken.w@163.com/工作同步/Code/Trans-Hub/packages/server/tests/e2e/cli/test_cli_smoke_flow.py:12: PytestUnknownMarkWarning: Unknown pytest.mark.e2e - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.e2e

tests/integration/workers/test_worker_run_once.py::test_worker_processes_draft_task_successfully
  /Users/saken/Library/CloudStorage/坚果云-saken.w@163.com/工作同步/Code/Trans-Hub/packages/server/src/trans_hub/infrastructure/persistence/repositories/_translation_repo.py:156: SAWarning: Usage of the 'Session.add()' operation is not currently supported within the execution stage of the flush process. Results may not be consistent.  Consider using alternative event listeners or connection-level operations instead.
    self._session.add(new_rev)

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED tests/integration/workers/test_worker_run_once.py::test_worker_processes_draft_task_successfully
=================== 1 failed, 6 passed, 8 warnings in 8.08s ====================
