# examples/06_integration_with_file_system.py
"""
Trans-Hub v3.0 ä¸æ–‡ä»¶ç³»ç»Ÿé›†æˆç¤ºä¾‹

æœ¬ç¤ºä¾‹æ¨¡æ‹Ÿäº†ä¸€ä¸ªå¸¸è§çš„ CI/CD åœºæ™¯ï¼š
1. è¯»å–ä¸€ä¸ªæºè¯­è¨€çš„ JSON å­—ç¬¦ä¸²æ–‡ä»¶ (e.g., `en.json`)ã€‚
2. éå†æ–‡ä»¶ä¸­çš„æ‰€æœ‰é”®å€¼å¯¹ï¼Œä¸ºå®ƒä»¬åˆ›å»ºç¿»è¯‘è¯·æ±‚ã€‚
3. å¯åŠ¨ Worker å¤„ç†æ‰€æœ‰è¯·æ±‚ã€‚
4. è·å–æ‰€æœ‰ç¿»è¯‘ç»“æœã€‚
5. å°†ç»“æœå†™å…¥ä¸€ä¸ªæ–°çš„ã€æŒ‰ç›®æ ‡è¯­è¨€å‘½åçš„ JSON æ–‡ä»¶ (e.g., `de.json`)ã€‚
"""
import asyncio
import json
import os
import sys
from pathlib import Path
from typing import Any, List, Tuple

import structlog

# --- è·¯å¾„è®¾ç½® ---
current_dir = Path(__file__).parent
project_root = current_dir.parent
sys.path.insert(0, str(project_root))
# ---

from trans_hub import Coordinator, TransHubConfig  # noqa: E402
from trans_hub.core.types import TranslationResult  # noqa: E402
from trans_hub.logging_config import setup_logging  # noqa: E402
from trans_hub.persistence import create_persistence_handler  # noqa: E402

# --- æ—¥å¿—é…ç½® ---
setup_logging(log_level="INFO")
log = structlog.get_logger(__name__)

# --- å‡†å¤‡æµ‹è¯•ç¯å¢ƒ ---
DB_FILE = "th_example_06.db"
SOURCE_LANG = "en"
TARGET_LANGS = ["de", "fr"]
SOURCE_FILE = Path("en.json")
OUTPUT_DIR = Path("translations_output")


SOURCE_CONTENT = {
    "app_title": "My Awesome App",
    "buttons": {
        "submit": "Submit",
        "cancel": "Cancel"
    },
    "errors": {
        "network_error": "Failed to connect to the server."
    }
}


async def main() -> None:
    """æ‰§è¡Œæ–‡ä»¶ç³»ç»Ÿé›†æˆç¤ºä¾‹ã€‚"""
    # å‡†å¤‡ç¯å¢ƒ
    if os.path.exists(DB_FILE):
        os.remove(DB_FILE)
    SOURCE_FILE.write_text(json.dumps(SOURCE_CONTENT, indent=2))
    OUTPUT_DIR.mkdir(exist_ok=True)

    config = TransHubConfig(database_url=f"sqlite:///{DB_FILE}", source_lang=SOURCE_LANG)
    handler = create_persistence_handler(config)
    coordinator = Coordinator(config=config, persistence_handler=handler)

    try:
        await coordinator.initialize()

        # 1. è¯»å–æºæ–‡ä»¶å¹¶æäº¤è¯·æ±‚
        log.info(f"ğŸš€ æ­¥éª¤ 1: è¯»å–æºæ–‡ä»¶ '{SOURCE_FILE}' å¹¶æäº¤æ‰€æœ‰ç¿»è¯‘è¯·æ±‚...")
        source_data = json.loads(SOURCE_FILE.read_text())
        
        # ä½¿ç”¨'ç‚¹åˆ†éš”'çš„é”®ä½œä¸º business_id
        flat_source = flatten_dict(source_data)
        for business_id, text in flat_source.items():
            await coordinator.request(
                business_id=business_id,
                source_payload={"text": text},
                target_langs=TARGET_LANGS,
            )
        log.info(f"âœ… å·²ä¸º {len(flat_source)} ä¸ªé”®æäº¤è¯·æ±‚ã€‚")

        # 2. Worker å¤„ç†
        async def process_translations_for_lang(language: str) -> None:
            # æ¶ˆè´¹å¼‚æ­¥ç”Ÿæˆå™¨
            async for _ in coordinator.process_pending_translations(language):
                pass

        log.info("ğŸ‘· æ­¥éª¤ 2: Worker æ­£åœ¨å¤„ç†æ‰€æœ‰ä»»åŠ¡...")
        worker_tasks: list[asyncio.Task[None]] = [
            asyncio.create_task(process_translations_for_lang(lang))
            for lang in TARGET_LANGS
        ]
        await asyncio.gather(*worker_tasks)
        log.info("âœ… æ‰€æœ‰ä»»åŠ¡å¤„ç†å®Œæ¯•ã€‚")

        # 3. è·å–ç»“æœå¹¶å†™å…¥æ–‡ä»¶
        log.info("ğŸ’¾ æ­¥éª¤ 3: è·å–ç»“æœå¹¶å†™å…¥ç›®æ ‡æ–‡ä»¶...")
        for lang in TARGET_LANGS:
            lang_results = {}
            for business_id, _ in flat_source.items():
                result = await coordinator.get_translation(
                    business_id=business_id, target_lang=lang
                )
                if result and result.translated_payload:
                    lang_results[business_id] = result.translated_payload.get("text")
            
            # å°†æ‰å¹³çš„å­—å…¸æ¢å¤ä¸ºåµŒå¥—ç»“æ„
            nested_results = unflatten_dict(lang_results)
            output_file = OUTPUT_DIR / f"{lang}.json"
            output_file.write_text(json.dumps(nested_results, indent=2, ensure_ascii=False))
            log.info(f"ğŸ‰ æˆåŠŸå†™å…¥æ–‡ä»¶: '{output_file}'")

    finally:
        await coordinator.close()
        # æ¸…ç†ç¯å¢ƒ
        if os.path.exists(DB_FILE):
            os.remove(DB_FILE)
        if SOURCE_FILE.exists():
            SOURCE_FILE.unlink()
        if OUTPUT_DIR.exists():
            import shutil
            shutil.rmtree(OUTPUT_DIR)


def flatten_dict(d: dict[str, Any], parent_key: str = '', sep: str ='.') -> dict[str, Any]:
    """å°†åµŒå¥—å­—å…¸æ‰å¹³åŒ–ã€‚"""
    items: List[Tuple[str, Any]] = []
    for k, v in d.items():
        new_key = parent_key + sep + k if parent_key else k
        if isinstance(v, dict):
            items.extend(flatten_dict(v, new_key, sep=sep).items())
        else:
            items.append((new_key, v))
    return dict(items)


def unflatten_dict(d: dict[str, Any], sep: str = '.') -> dict[str, Any]:
    """å°†æ‰å¹³å­—å…¸æ¢å¤ä¸ºåµŒå¥—ç»“æ„ã€‚"""
    result: dict[str, Any] = {}
    for key, value in d.items():
        parts = key.split(sep)
        d_ref = result
        for part in parts[:-1]:
            if part not in d_ref:
                d_ref[part] = {}
            d_ref = d_ref[part]
        d_ref[parts[-1]] = value
    return result


if __name__ == "__main__":
    asyncio.run(main())
    