# examples/06_integration_with_file_system.py
"""
Trans-Hub v3.0 ä¸æ–‡ä»¶ç³»ç»Ÿé›†æˆç¤ºä¾‹

æœ¬ç¤ºä¾‹æ¨¡æ‹Ÿäº†ä¸€ä¸ªå¸¸è§çš„ CI/CD åœºæ™¯ï¼š
1. è¯»å–ä¸€ä¸ªæºè¯­è¨€çš„ JSON å­—ç¬¦ä¸²æ–‡ä»¶ (e.g., `en.json`)ã€‚
2. éå†æ–‡ä»¶ä¸­çš„æ‰€æœ‰é”®å€¼å¯¹ï¼Œä¸ºå®ƒä»¬åˆ›å»ºç¿»è¯‘è¯·æ±‚ã€‚
3. å¯åŠ¨ Worker å¤„ç†æ‰€æœ‰è¯·æ±‚ã€‚
4. è·å–æ‰€æœ‰ç¿»è¯‘ç»“æœã€‚
5. å°†ç»“æœå†™å…¥ä¸€ä¸ªæ–°çš„ã€æŒ‰ç›®æ ‡è¯­è¨€å‘½åçš„ JSON æ–‡ä»¶ (e.g., `de.json`)ã€‚

è¿è¡Œæ–¹å¼:
åœ¨é¡¹ç›®æ ¹ç›®å½•æ‰§è¡Œ: `poetry run python examples/06_integration_with_file_system.py`
"""
import asyncio
import json
import os
import sys
from pathlib import Path
from typing import Any, Dict, List, Tuple

import structlog

# --- è·¯å¾„è®¾ç½® ---
current_dir = Path(__file__).parent
project_root = current_dir.parent
sys.path.insert(0, str(project_root))
# ---

from trans_hub import Coordinator, TransHubConfig  # noqa: E402
from trans_hub.core.types import TranslationResult  # noqa: E402
from trans_hub.db.schema_manager import apply_migrations  # noqa: E402
from trans_hub.logging_config import setup_logging  # noqa: E402
from trans_hub.persistence import create_persistence_handler  # noqa: E402

# --- æ—¥å¿—é…ç½® ---
setup_logging(log_level="INFO")
log = structlog.get_logger("trans_hub")

# --- å‡†å¤‡æµ‹è¯•ç¯å¢ƒ ---
current_dir = Path(__file__).parent
DB_FILE = current_dir / "th_example_06.db"
SOURCE_LANG = "en"
TARGET_LANGS = ["de", "fr"]
SOURCE_FILE = current_dir / "en.json"
OUTPUT_DIR = current_dir / "translations_output"

SOURCE_CONTENT = {
    "app_title": "My Awesome App",
    "buttons": {"submit": "Submit", "cancel": "Cancel"},
    "errors": {"network_error": "Failed to connect to the server."},
}


async def main() -> None:
    """æ‰§è¡Œæ–‡ä»¶ç³»ç»Ÿé›†æˆç¤ºä¾‹ã€‚"""
    if DB_FILE.exists():
        DB_FILE.unlink()
    SOURCE_FILE.write_text(json.dumps(SOURCE_CONTENT, indent=2, ensure_ascii=False))
    if OUTPUT_DIR.exists():
        import shutil
        shutil.rmtree(OUTPUT_DIR)
    OUTPUT_DIR.mkdir(exist_ok=True)

    config = TransHubConfig(
        database_url=f"sqlite:///{DB_FILE.resolve()}", source_lang=SOURCE_LANG
    )
    apply_migrations(config.db_path)
    handler = create_persistence_handler(config)
    coordinator = Coordinator(config=config, persistence_handler=handler)

    try:
        await coordinator.initialize()
        log.info("âœ… åè°ƒå™¨åˆå§‹åŒ–æˆåŠŸ", db_path=str(DB_FILE))

        log.info(f"ğŸš€ æ­¥éª¤ 1: è¯»å–æºæ–‡ä»¶ '{SOURCE_FILE}' å¹¶æäº¤æ‰€æœ‰ç¿»è¯‘è¯·æ±‚...")
        source_data = json.loads(SOURCE_FILE.read_text())
        flat_source = flatten_dict(source_data)
        for business_id, text in flat_source.items():
            await coordinator.request(
                business_id=business_id,
                source_payload={"text": text},
                target_langs=TARGET_LANGS,
            )
        log.info(f"âœ… å·²ä¸º {len(flat_source)} ä¸ªé”®æäº¤è¯·æ±‚ã€‚")

        log.info("ğŸ‘· æ­¥éª¤ 2: Worker æ­£åœ¨å¤„ç†æ‰€æœ‰ä»»åŠ¡...")
        await process_translations(coordinator, TARGET_LANGS)
        log.info("âœ… æ‰€æœ‰ä»»åŠ¡å¤„ç†å®Œæ¯•ã€‚")

        log.info("ğŸ’¾ æ­¥éª¤ 3: è·å–ç»“æœå¹¶å†™å…¥ç›®æ ‡æ–‡ä»¶...")
        for lang in TARGET_LANGS:
            lang_results: Dict[str, Any] = {}
            for business_id, _ in flat_source.items():
                result = await coordinator.get_translation(
                    business_id=business_id, target_lang=lang
                )
                if result and result.translated_payload:
                    lang_results[business_id] = result.translated_payload.get("text")

            nested_results = unflatten_dict(lang_results)
            output_file = OUTPUT_DIR / f"{lang}.json"
            output_file.write_text(
                json.dumps(nested_results, indent=2, ensure_ascii=False)
            )
            log.info(f"ğŸ‰ æˆåŠŸå†™å…¥æ–‡ä»¶: '{output_file}'")

    finally:
        await coordinator.close()
        log.info("ğŸšª åè°ƒå™¨å·²å…³é—­")
        if DB_FILE.exists():
            DB_FILE.unlink()
        if SOURCE_FILE.exists():
            SOURCE_FILE.unlink()
        if OUTPUT_DIR.exists():
            import shutil
            shutil.rmtree(OUTPUT_DIR)


def flatten_dict(d: Dict[str, Any], parent_key: str = "", sep: str = ".") -> Dict[str, str]:
    items: List[Tuple[str, str]] = []
    for k, v in d.items():
        new_key = parent_key + sep + k if parent_key else k
        if isinstance(v, dict):
            items.extend(flatten_dict(v, new_key, sep=sep).items())
        else:
            items.append((new_key, str(v)))
    return dict(items)


def unflatten_dict(d: Dict[str, Any], sep: str = ".") -> Dict[str, Any]:
    result: Dict[str, Any] = {}
    for key, value in d.items():
        parts = key.split(sep)
        d_ref = result
        for part in parts[:-1]:
            if part not in d_ref:
                d_ref[part] = {}
            d_ref = d_ref[part]
        d_ref[parts[-1]] = value
    return result


async def process_translations(coordinator: Coordinator, langs: List[str]) -> None:
    """æ¨¡æ‹Ÿ Worker å¤„ç†æ‰€æœ‰å¾…åŠä»»åŠ¡ã€‚"""
    tasks = [asyncio.create_task(consume_all(coordinator, lang)) for lang in langs]
    await asyncio.gather(*tasks)


async def consume_all(coordinator: Coordinator, lang: str) -> None:
    """æ¶ˆè´¹æŒ‡å®šè¯­è¨€çš„æ‰€æœ‰å¾…åŠä»»åŠ¡ã€‚"""
    results: List[TranslationResult] = [
        res async for res in coordinator.process_pending_translations(lang)
    ]
    log.info(f"Worker ä¸ºè¯­è¨€ '{lang}' å¤„ç†äº† {len(results)} ä¸ªä»»åŠ¡ã€‚")


if __name__ == "__main__":
    asyncio.run(main())