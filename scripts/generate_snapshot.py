#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Trans-Hub Monorepo é¡¹ç›®å¿«ç…§ç”Ÿæˆå·¥å…·ï¼ˆçº¯æ ‡å‡†åº“ç‰ˆ v6.3ï¼‰

æ”¹åŠ¨è¦ç‚¹ï¼š
- æ‰«ææ ¹ä¸è¾“å‡ºä½ç½®æ˜ç¡®ï¼š
  * æ‰«ææ ¹ï¼šè‡ªåŠ¨å‘ä¸Šé€‰æ‹©â€œæœ€é«˜ç¥–å…ˆçš„ä»“åº“æ ¹â€ï¼ˆä¼˜å…ˆå« packages/ï¼›å…¶æ¬¡ .git/ï¼›å†æ¬¡ pyproject.tomlï¼‰
  * è¾“å‡ºæ–‡ä»¶ï¼šé»˜è®¤å§‹ç»ˆå†™åˆ°â€œè„šæœ¬æ‰€åœ¨ç›®å½•â€ï¼ˆå³ scripts/ åŒç›®å½•ï¼‰ï¼Œæ»¡è¶³â€œç”Ÿæˆæ”¾åœ¨åŒç›®å½•ä¸‹â€è¯‰æ±‚
- ä»å¯è‡ªå®šä¹‰æ–‡ä»¶åï¼š--output project_snapshot.txt
- å…¶ä»–ï¼šç›®å½•æ ‘ + æ–‡ä»¶å†…å®¹ï¼ˆæˆªæ–­/è·³è¿‡äºŒè¿›åˆ¶ï¼‰ï¼Œ--extra/--no-content/--max-bytesï¼›æ”¯æŒ --scan-rootã€--debug

ç”¨æ³•ï¼š
  # ä»»æ„ç›®å½•æ‰§è¡Œï¼Œå¿«ç…§ä¼šå†™åˆ°è„šæœ¬åŒç›®å½•ï¼ˆscripts/ï¼‰
  python3 scripts/generate_snapshot.py

  # æŒ‡å®šæ‰«ææ ¹
  python3 scripts/generate_snapshot.py --scan-root /path/to/Trans-Hub

  # åªè¾“å‡ºç›®å½•æ ‘
  python3 scripts/generate_snapshot.py --no-content

  # é¢å¤–åŒ…å«è·¯å¾„ï¼ˆç›¸å¯¹æ‰«ææ ¹ï¼‰
  python3 scripts/generate_snapshot.py --extra .github configs

é€€å‡ºç ï¼š0 æˆåŠŸï¼›é 0 ä¸ºé”™è¯¯
"""

from __future__ import annotations

import argparse
import io
import sys
from datetime import datetime
from pathlib import Path
from typing import IO, Iterable

import structlog

logger = structlog.get_logger()

# -------- å¯è°ƒå‚æ•° --------
DEFAULT_DIRS = ["packages", "scripts", "docs", "alembic", "migrations"]
DEFAULT_ROOT_FILES = [
    ".env.example",
    "pyproject.toml",
    "poetry.toml",
    "README.md",
    "alembic.ini",
    ".gitignore",
    "ruff.toml",
    ".flake8",
    ".editorconfig",
    "LICENSE",
]
EXCLUDE_NAMES = {
    "__pycache__",
    ".git",
    ".idea",
    ".vscode",
    ".pytest_cache",
    ".mypy_cache",
    ".ruff_cache",
    ".venv",
    "venv",
    "node_modules",
    "dist",
    "build",
    ".DS_Store",
    "Thumbs.db",
    "poetry.lock",
    "package-lock.json",
    "pnpm-lock.yaml",
    ".coverage",
    "htmlcov",
    "temp",
}
BINARY_EXTS = {
    ".png",
    ".jpg",
    ".jpeg",
    ".webp",
    ".gif",
    ".svg",
    ".ico",
    ".pdf",
    ".zip",
    ".tar",
    ".gz",
    ".7z",
    ".so",
    ".dylib",
    ".dll",
    ".wasm",
    ".db",
}
LANG_MAP = {
    ".py": "python",
    ".toml": "toml",
    ".ini": "ini",
    ".yml": "yaml",
    ".yaml": "yaml",
    ".json": "json",
    ".sql": "sql",
    ".md": "markdown",
    ".sh": "bash",
    ".ps1": "powershell",
    ".ts": "typescript",
    ".tsx": "tsx",
    ".js": "javascript",
    ".jsx": "jsx",
    ".css": "css",
    ".html": "html",
    ".env": "bash",
}


# -------- æ ¹ç›®å½•å‘ç°ï¼ˆä¼˜é€‰æœ€é«˜ç¥–å…ˆï¼‰ --------
def looks_like_repo_root(path: Path) -> tuple[bool, bool, bool]:
    """è¿”å› (has_packages, has_git, has_pyproject) ä¸‰å…ƒå¸ƒå°”ã€‚"""
    return (
        (path / "packages").is_dir(),
        (path / ".git").exists(),
        (path / "pyproject.toml").is_file(),
    )


def find_best_repo_root(start: Path, debug: bool = False) -> Path | None:
    """
    è‡ª start å‘ä¸Šéå†åˆ°ç£ç›˜æ ¹ï¼Œæ”¶é›†æ‰€æœ‰å€™é€‰ï¼Œæœ€ç»ˆæŒ‰ä¼˜å…ˆçº§å–â€œæœ€é«˜â€ç¥–å…ˆï¼š
      1) å« packages/ çš„ç›®å½•ï¼ˆMonorepo æ ¹ï¼Œæœ€é«˜ä¼˜å…ˆï¼‰
      2) å« .git/ çš„ç›®å½•
      3) å« pyproject.toml çš„ç›®å½•
    """
    cur = start.resolve()
    best_packages: Path | None = None
    best_git: Path | None = None
    best_py: Path | None = None
    chain: list[str] = []

    while True:
        has_packages, has_git, has_py = looks_like_repo_root(cur)
        if debug:
            chain.append(
                f"{cur}  [packages={has_packages}, git={has_git}, py={has_py}]"
            )
        if has_packages:
            best_packages = cur  # è¶Šå¾€ä¸Šè¦†ç›–ä¸ºâ€œæ›´é«˜ç¥–å…ˆâ€
        if has_git:
            best_git = cur
        if has_py:
            best_py = cur
        if cur.parent == cur:
            break
        cur = cur.parent

    if debug:
        print("ğŸ” æ ¹ç›®å½•å‘ä¸Šæœç´¢é“¾ï¼š")
        for line in chain:
            print(" -", line)

    return best_packages or best_git or best_py


# -------- æ‰«æä¸è¿‡æ»¤ --------
def iter_targets(scan_root: Path, extra: list[str]) -> list[Path]:
    """ç”Ÿæˆæ‰«æèµ·ç‚¹ï¼šé»˜è®¤ç›®å½• + é¢å¤–è·¯å¾„ + é»˜è®¤æ ¹æ–‡ä»¶ï¼ˆç›¸å¯¹æ‰«ææ ¹ï¼‰ã€‚"""
    targets: list[Path] = []
    for d in DEFAULT_DIRS:
        p = (scan_root / d).resolve()
        if p.exists():
            targets.append(p)
    for e in extra:
        p = (scan_root / e).resolve()
        if p.exists():
            targets.append(p)
        else:
            print(f"[æç¤º] å¿½ç•¥ä¸å­˜åœ¨çš„è·¯å¾„ï¼š{e}", file=sys.stderr)
    for f in DEFAULT_ROOT_FILES:
        p = (scan_root / f).resolve()
        if p.exists():
            targets.append(p)
    return sorted(set(targets))


def should_exclude(path: Path) -> bool:
    """åç§°çº§æ’é™¤ï¼ˆå‘½ä¸­ä»»ä¸€çˆ¶çº§äº¦æ’é™¤ï¼‰ã€‚"""
    if path.name in EXCLUDE_NAMES:
        return True
    return any(parent.name in EXCLUDE_NAMES for parent in path.parents)


def walk_files(scan_root: Path, targets: Iterable[Path]) -> list[Path]:
    """é€’å½’æ”¶é›†æ–‡ä»¶ï¼Œç›¸å¯¹ scan_root è¿”å›ã€‚"""
    result: list[Path] = []
    for entry in targets:
        if should_exclude(entry):
            continue
        if entry.is_file():
            result.append(entry.relative_to(scan_root))
            continue
        if entry.is_dir():
            for p in sorted(entry.rglob("*")):
                if should_exclude(p):
                    continue
                if p.is_file():
                    result.append(p.relative_to(scan_root))
    return sorted(set(result))


# -------- å†…å®¹è¾“å‡º --------
def detect_binary(path: Path) -> bool:
    """ç²—ç•¥äºŒè¿›åˆ¶åˆ¤æ–­ï¼šåç¼€æˆ–é¦– 4KB å« NULï¼›å¼‚å¸¸ä¿å®ˆä¸ºäºŒè¿›åˆ¶ã€‚"""
    if path.suffix.lower() in BINARY_EXTS:
        return True
    try:
        with open(path, "rb") as f:
            chunk = f.read(4096)
            if b"\\x00" in chunk:
                return True
            try:
                chunk.decode("utf-8")
            except UnicodeDecodeError:
                # å¯èƒ½æ˜¯å…¶å®ƒç¼–ç æ–‡æœ¬ï¼Œå…ˆä¸æ®æ­¤åˆ¤äºŒè¿›åˆ¶
                pass
    except OSError:
        return True
    return False


def code_lang_for(path: Path) -> str:
    return LANG_MAP.get(path.suffix.lower(), (path.suffix.lstrip(".") or "text"))


def write_dir_tree(scan_root: Path, files: list[Path], out: IO[str]) -> None:
    out.write("## ç›®å½•ç»“æ„\n\n")
    tree: dict[str, dict] = {}
    for rel in files:
        node = tree
        for part in rel.parts:
            node = node.setdefault(part, {})

    def render(node: dict[str, dict], indent: str = "") -> None:
        items = sorted(node.items(), key=lambda kv: kv[0])
        for i, (name, sub) in enumerate(items):
            connector = "â””â”€â”€ " if i == len(items) - 1 else "â”œâ”€â”€ "
            out.write(f"{indent}{connector}{name}\n")
            if sub:
                render(sub, indent + ("    " if i == len(items) - 1 else "â”‚   "))

    render(tree)
    out.write("\n")


def write_file_contents(
    scan_root: Path, files: list[Path], out: IO[str], max_bytes: int, no_content: bool
) -> None:
    out.write("## æ–‡ä»¶å†…å®¹\n\n")
    if no_content:
        out.write("_å·²æ ¹æ® --no-content è·³è¿‡æ–‡ä»¶å†…å®¹ï¼Œä»…å±•ç¤ºç›®å½•ç»“æ„ã€‚_\n")
        return
    for rel in files:
        abs_path = (scan_root / rel).resolve()
        out.write(f"### `{rel.as_posix()}`\n\n")
        if detect_binary(abs_path):
            out.write("```text\n[äºŒè¿›åˆ¶æˆ–é UTF-8 çº¯æ–‡æœ¬æ–‡ä»¶ï¼Œå·²è·³è¿‡å†…å®¹]\n```\n\n")
            continue
        try:
            with open(abs_path, "rb") as f:
                data = f.read(max_bytes + 1)
            truncated = len(data) > max_bytes
            if truncated:
                data = data[:max_bytes]
            text = data.decode("utf-8", errors="replace").strip()
            out.write(f"```{code_lang_for(abs_path)}\n{text}\n```\n\n")
            if truncated:
                out.write(
                    f"> âš ï¸ æ–‡ä»¶è¿‡å¤§ï¼Œå·²æŒ‰ --max-bytes={max_bytes} æˆªæ–­ï¼Œä»…å±•ç¤ºå‰éƒ¨å†…å®¹ã€‚\n\n"
                )
        except Exception as e:
            out.write(f"```text\n[æ— æ³•è¯»å–æ–‡ä»¶å†…å®¹: {e}]\n```\n\n")


# -------- å…¥å£ --------
def main() -> None:
    parser = argparse.ArgumentParser(
        prog="generate_snapshot",
        description="ç”Ÿæˆ Trans-Hub çš„é¡¹ç›®å¿«ç…§ï¼ˆç›®å½•æ ‘ + æ–‡ä»¶å†…å®¹ï¼‰ã€‚æ‰«ææ ¹è‡ªåŠ¨å‘ä¸Šå‘ç°ï¼ˆä¼˜å…ˆ packages/ï¼‰ã€‚",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
    parser.add_argument(
        "-o",
        "--output",
        type=str,
        default="project_snapshot.txt",
        help="è¾“å‡ºæ–‡ä»¶åï¼ˆå†™å…¥åˆ°è„šæœ¬æ‰€åœ¨ç›®å½•ï¼‰ã€‚",
    )
    parser.add_argument(
        "--max-bytes",
        type=int,
        default=512 * 1024,
        help="å•æ–‡ä»¶æœ€å¤§è¯»å–å­—èŠ‚æ•°ï¼ˆè¶…è¿‡æˆªæ–­ï¼‰ã€‚",
    )
    parser.add_argument(
        "--no-content", action="store_true", help="ä»…è¾“å‡ºç›®å½•æ ‘ï¼Œä¸å†™æ–‡ä»¶å†…å®¹ã€‚"
    )
    parser.add_argument(
        "--extra", nargs="*", default=[], help="é¢å¤–åŒ…å«è·¯å¾„ï¼ˆç›¸å¯¹æ‰«ææ ¹ï¼‰ã€‚"
    )
    parser.add_argument(
        "--scan-root",
        type=str,
        default="",
        help="æ‰‹å·¥æŒ‡å®šæ‰«ææ ¹ï¼›ç•™ç©ºåˆ™è‡ªåŠ¨ä» CWD å‘ä¸ŠæŸ¥æ‰¾ã€‚",
    )
    parser.add_argument("--debug", action="store_true", help="æ‰“å°æ ¹ç›®å½•åˆ¤å®šè¿‡ç¨‹ã€‚")
    args = parser.parse_args()

    # 1) æ‰«ææ ¹ï¼šè‡ªåŠ¨å‘ä¸Šæ‰¾â€œæœ€é«˜ç¥–å…ˆâ€
    cwd = Path.cwd().resolve()
    if args.scan_root:
        scan_root = Path(args.scan_root).resolve()
        if not scan_root.exists():
            print(f"é”™è¯¯ï¼šæŒ‡å®šçš„æ‰«ææ ¹ä¸å­˜åœ¨ï¼š{scan_root}", file=sys.stderr)
            sys.exit(2)
    else:
        found = find_best_repo_root(cwd, debug=args.debug)
        if not found:
            print(
                "é”™è¯¯ï¼šæœªèƒ½è‡ªåŠ¨å‘ç°ä»“åº“æ ¹ã€‚\n"
                "è¯·ä½¿ç”¨ --scan-root æŒ‡å®šå« packages/ æˆ– .git/ æˆ– pyproject.toml çš„ç›®å½•ã€‚",
                file=sys.stderr,
            )
            sys.exit(2)
        scan_root = found

    # 2) è¾“å‡ºä½ç½®ï¼šå§‹ç»ˆå†™åˆ°â€œè„šæœ¬æ‰€åœ¨ç›®å½•â€
    script_dir = Path(__file__).resolve().parent
    output_path = script_dir / args.output

    # åœ¨å†™å…¥æ–°å†…å®¹ä¹‹å‰ï¼Œå…ˆåˆ é™¤æˆ–æ¸…ç©ºè¾“å‡ºæ–‡ä»¶
    try:
        if output_path.exists():
            output_path.unlink()
            print(f"ğŸ”„ å·²åˆ é™¤æ—§æ–‡ä»¶: {output_path}")
    except OSError as e:
        print(f"âš ï¸ æ— æ³•åˆ é™¤æ—§æ–‡ä»¶ {output_path}: {e}", file=sys.stderr)
        # å°è¯•æ¸…ç©ºæ–‡ä»¶å†…å®¹è€Œä¸æ˜¯åˆ é™¤
        try:
            with open(output_path, "w", encoding="utf-8") as f:
                f.write("")
            print(f"ğŸ”„ å·²æ¸…ç©ºæ—§æ–‡ä»¶å†…å®¹: {output_path}")
        except OSError as e2:
            print(f"âŒ æ— æ³•æ¸…ç©ºæ—§æ–‡ä»¶ {output_path}: {e2}", file=sys.stderr)
            sys.exit(3)

    targets = iter_targets(scan_root, args.extra)
    files = walk_files(scan_root, targets)

    logger.info("ğŸš€ å¼€å§‹ç”Ÿæˆé¡¹ç›®å¿«ç…§")
    logger.info(
        "å¼€å§‹ç”Ÿæˆé¡¹ç›®å¿«ç…§",
        æ‰«ææ ¹ç›®å½•=str(scan_root),
        è„šæœ¬ç›®å½•=str(script_dir),
        è¾“å‡ºæ–‡ä»¶=output_path.name
    )
    logger.info(
        "æ‰«æé…ç½®",
        åŒ…å«èµ·ç‚¹=', '.join(p.as_posix() for p in targets) if targets else '(ç©º)',
        æ–‡ä»¶æ€»æ•°=len(files),
        æ¨¡å¼="ä»…ç›®å½•æ ‘ï¼ˆ--no-contentï¼‰" if args.no_content else "å®Œæ•´å†…å®¹",
        æœ€å¤§å­—èŠ‚=args.max_bytes
    )

    with io.open(output_path, "w", encoding="utf-8", newline="\n") as out:
        out.write(
            f"# Trans-Hub Monorepo é¡¹ç›®å¿«ç…§ï¼ˆ{datetime.now().strftime('%Y-%m-%d %H:%M')}ï¼‰\n\n"
        )
        out.write(
            "> è¯´æ˜ï¼šæœ¬æ–‡ä»¶ç”±è„šæœ¬è‡ªåŠ¨ç”Ÿæˆï¼ŒåŒ…å«ç›®å½•ç»“æ„ä¸æ ¸å¿ƒæ–‡ä»¶å†…å®¹ï¼ˆå¯èƒ½æˆªæ–­ï¼‰ã€‚\n\n"
        )
        write_dir_tree(scan_root, files, out)
        write_file_contents(scan_root, files, out, args.max_bytes, args.no_content)

    logger.info("å¿«ç…§ç”Ÿæˆå®Œæˆ", è¾“å‡ºè·¯å¾„=str(output_path))


if __name__ == "__main__":
    main()
