import os
import time
import uuid

import structlog
from dotenv import load_dotenv

from trans_hub.config import EngineConfigs, TransHubConfig
from trans_hub.coordinator import Coordinator
from trans_hub.db.schema_manager import apply_migrations
from trans_hub.engine_registry import ENGINE_REGISTRY
from trans_hub.engines.debug import DebugEngineConfig
from trans_hub.engines.openai import OpenAIEngineConfig
from trans_hub.logging_config import setup_logging
from trans_hub.persistence import DefaultPersistenceHandler
from trans_hub.rate_limiter import RateLimiter
from trans_hub.types import TranslationStatus


def test_rate_limiter():
    log = structlog.get_logger("test_rate_limiter")
    log.info("--- å¼€å§‹é€Ÿç‡é™åˆ¶å™¨åŠŸèƒ½æµ‹è¯• ---")
    db_file = "transhub_ratelimit_test.db"
    if os.path.exists(db_file):
        os.remove(db_file)
    apply_migrations(db_file)
    handler = DefaultPersistenceHandler(db_path=db_file)
    rate_limiter = RateLimiter(refill_rate=2, capacity=1)
    config = TransHubConfig(
        database_url=f"sqlite:///{db_file}",
        active_engine="debug",
        engine_configs=EngineConfigs(debug=DebugEngineConfig()),
    )
    coordinator = Coordinator(
        config=config, persistence_handler=handler, rate_limiter=rate_limiter
    )
    try:
        coordinator.request(target_langs=["jp"], text_content="a")
        coordinator.request(target_langs=["jp"], text_content="b")
        coordinator.request(target_langs=["jp"], text_content="c")
        start_time = time.monotonic()
        results = list(
            coordinator.process_pending_translations(
                target_lang="jp", batch_size=1, max_retries=0
            )
        )
        duration = time.monotonic() - start_time
        log.info("é€Ÿç‡é™åˆ¶æµ‹è¯•å®Œæˆ", duration=f"{duration:.2f}s")
        assert len(results) == 3
        assert duration > 0.95, f"é€Ÿç‡é™åˆ¶å™¨æœªç”Ÿæ•ˆ (duration: {duration:.2f}s)"
        log.info("âœ… é€Ÿç‡é™åˆ¶å™¨æµ‹è¯•æˆåŠŸï¼")
    finally:
        coordinator.close()


def test_retry_logic():
    log = structlog.get_logger("test_retry_logic")
    log.info("--- å¼€å§‹é‡è¯•é€»è¾‘æµ‹è¯• ---")
    db_file = "transhub_retry_test.db"
    if os.path.exists(db_file):
        os.remove(db_file)
    apply_migrations(db_file)
    handler = DefaultPersistenceHandler(db_path=db_file)
    debug_config_with_failure = DebugEngineConfig(
        fail_on_text="cherry", fail_is_retryable=True
    )
    config = TransHubConfig(
        database_url=f"sqlite:///{db_file}",
        active_engine="debug",
        engine_configs=EngineConfigs(debug=debug_config_with_failure),
    )
    coordinator = Coordinator(config=config, persistence_handler=handler)
    try:
        coordinator.request(target_langs=["jp"], text_content="apple")
        coordinator.request(target_langs=["jp"], text_content="cherry")
        results = list(
            coordinator.process_pending_translations(
                target_lang="jp", max_retries=1, initial_backoff=0.1
            )
        )
        log.info("é‡è¯•é€»è¾‘æµ‹è¯•å®Œæˆ", results_count=len(results))
        cherry_result = next(r for r in results if r.original_content == "cherry")
        assert cherry_result.status == TranslationStatus.FAILED
        log.info("âœ… é‡è¯•é€»è¾‘æµ‹è¯•æˆåŠŸï¼")
    finally:
        coordinator.close()


def test_garbage_collection():
    log = structlog.get_logger("test_gc")
    log.info("--- å¼€å§‹åƒåœ¾å›æ”¶ (GC) æµ‹è¯• ---")
    db_file = "transhub_gc_test.db"
    if os.path.exists(db_file):
        os.remove(db_file)
    apply_migrations(db_file)
    handler = DefaultPersistenceHandler(db_path=db_file)
    config = TransHubConfig(
        database_url=f"sqlite:///{db_file}",
        active_engine="debug",
        engine_configs=EngineConfigs(),
    )
    coordinator = Coordinator(config=config, persistence_handler=handler)
    try:
        with handler.transaction() as cursor:
            cursor.execute(
                "INSERT INTO th_content (id, value, created_at) VALUES (1, 'old_content', '2020-01-01 10:00:00')"
            )
            cursor.execute(
                "INSERT INTO th_content (id, value) VALUES (2, 'active_content')"
            )
            cursor.execute(
                "INSERT INTO th_content (id, value, created_at) VALUES (3, 'orphan_content', '2020-01-01 11:00:00')"
            )
            cursor.execute(
                "INSERT INTO th_sources (business_id, content_id, last_seen_at) VALUES ('source:old', 1, '2020-01-01 10:00:00')"
            )
            cursor.execute(
                "INSERT INTO th_sources (business_id, content_id, last_seen_at) VALUES ('source:active', 2, ?)",
                (time.strftime("%Y-%m-%d %H:%M:%S"),),
            )
        stats_dry = coordinator.run_garbage_collection(
            retention_days=1000, dry_run=True
        )
        assert stats_dry["deleted_sources"] == 1 and stats_dry["deleted_content"] == 1
        stats_real = coordinator.run_garbage_collection(
            retention_days=1000, dry_run=False
        )
        assert stats_real["deleted_sources"] == 1 and stats_real["deleted_content"] == 2
        with handler.transaction() as cursor:
            cursor.execute("SELECT COUNT(*) FROM th_content")
            assert cursor.fetchone()[0] == 1
        log.info("âœ… åƒåœ¾å›æ”¶ (GC) æµ‹è¯•æˆåŠŸï¼")
    finally:
        coordinator.close()


def test_openai_engine_flow():
    log = structlog.get_logger("test_openai_engine")
    if "openai" not in ENGINE_REGISTRY:
        log.warning("OpenAI å¼•æ“æœªè¢«åŠ è½½ï¼Œè·³è¿‡æµ‹è¯•ã€‚")
        return
    log.info("--- å¼€å§‹ OpenAI å¼•æ“æµç¨‹æµ‹è¯• ---")
    db_file = "transhub_openai_test.db"
    if os.path.exists(db_file):
        os.remove(db_file)
    apply_migrations(db_file)
    handler = DefaultPersistenceHandler(db_path=db_file)
    try:
        config = TransHubConfig(
            database_url=f"sqlite:///{db_file}",
            active_engine="openai",
            engine_configs=EngineConfigs(openai=OpenAIEngineConfig()),
        )
        if not config.engine_configs.openai.base_url:
            log.warning("æœªæ‰¾åˆ° TH_OPENAI_ENDPOINT é…ç½®ï¼Œè·³è¿‡ OpenAI å¼•æ“æµ‹è¯•ã€‚")
            return
    except Exception as e:
        log.warning("åŠ è½½æˆ–éªŒè¯ OpenAI é…ç½®æ—¶å‡ºé”™ï¼Œè·³è¿‡æµ‹è¯•", error=str(e))
        return
    coordinator = Coordinator(config=config, persistence_handler=handler)
    try:
        text_to_translate = "Hello, world!"
        target_lang = "Spanish"
        coordinator.request(target_langs=[target_lang], text_content=text_to_translate)
        results = list(
            coordinator.process_pending_translations(target_lang=target_lang)
        )
        assert len(results) == 1
        result = results[0]
        log.info("ç¿»è¯‘ç»“æœ", result=result)
        if result.status == TranslationStatus.TRANSLATED:
            assert "Hola, mundo" in result.translated_content
            log.info("âœ… OpenAI å¼•æ“æµ‹è¯•æˆåŠŸï¼(API Key æœ‰æ•ˆ)")
        elif result.status == TranslationStatus.FAILED:
            assert result.error is not None
            if "401" in result.error:
                log.warning("âœ… æµ‹è¯•æ”¶åˆ° 401 é”™è¯¯ï¼Œå¼•æ“é”™è¯¯å¤„ç†é€»è¾‘å·¥ä½œæ­£å¸¸ã€‚")
            else:
                raise AssertionError(f"å‘ç”Ÿé 401 çš„æ„å¤–é”™è¯¯: {result.error}")
        else:
            raise AssertionError(f"ç¿»è¯‘ç»“æœçŠ¶æ€å¼‚å¸¸: {result.status}")
    finally:
        coordinator.close()


def main():
    if load_dotenv():
        print("âœ… .env æ–‡ä»¶å·²åŠ è½½ã€‚")
    else:
        print("âš ï¸ æœªæ‰¾åˆ° .env æ–‡ä»¶ã€‚")
    setup_logging(log_level="INFO", log_format="console")
    correlation_id = str(uuid.uuid4())
    structlog.contextvars.bind_contextvars(correlation_id=correlation_id)
    root_log = structlog.get_logger("main_test_runner")
    root_log.info("======== Trans-Hub v1.0 æœ€ç»ˆåŠŸèƒ½éªŒè¯å¼€å§‹ ========")
    try:
        test_rate_limiter()
        test_retry_logic()
        test_garbage_collection()
        test_openai_engine_flow()
        root_log.info("ğŸ‰ ======== æ‰€æœ‰æµ‹è¯•æˆåŠŸé€šè¿‡ï¼Trans-Hub v1.0 æ ¸å¿ƒåŠŸèƒ½å®Œæˆï¼ ======== ğŸ‰")
    except Exception:
        root_log.error("âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿæœªæ•è·çš„å¼‚å¸¸ï¼", exc_info=True)
        raise
    finally:
        structlog.contextvars.clear_contextvars()


if __name__ == "__main__":
    main()
