"""
run_coordinator_test.py (v1.0.1 Final, Corrected)

Trans-Hub v1.0 æœ€ç»ˆåŠŸèƒ½éªŒè¯è„šæœ¬ã€‚
å®ƒéµå¾ªæœ€ä½³å®è·µï¼Œåœ¨ç¨‹åºå…¥å£å¤„ä¸»åŠ¨åŠ è½½ .env æ–‡ä»¶ï¼Œ
å¹¶å¯¹æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½è¿›è¡Œç«¯åˆ°ç«¯æµ‹è¯•ã€‚
"""
import os
import time
import uuid
from dotenv import load_dotenv

import structlog
from trans_hub.logging_config import setup_logging
from trans_hub.coordinator import Coordinator
from trans_hub.db.schema_manager import apply_migrations
from trans_hub.engines.debug import DebugEngine, DebugEngineConfig
from trans_hub.engines.openai import OpenAIEngine, OpenAIEngineConfig
from trans_hub.persistence import DefaultPersistenceHandler
from trans_hub.rate_limiter import RateLimiter
from trans_hub.types import TranslationStatus, TranslationResult


# ==============================================================================
#  æµ‹è¯•å¥—ä»¶å‡½æ•°
# ==============================================================================

def test_core_flow_with_debug_engine():
    """
    æµ‹è¯•æ ¸å¿ƒå·¥ä½œæµï¼ˆè¯·æ±‚ã€å¤„ç†ã€é‡è¯•ã€é€Ÿç‡é™åˆ¶ï¼‰ä½¿ç”¨ DebugEngineã€‚
    è¿™ä¸ªæµ‹è¯•å¿«é€Ÿã€æ— å¤–éƒ¨ä¾èµ–ï¼Œé€‚åˆåœ¨ CI ç¯å¢ƒä¸­é¢‘ç¹è¿è¡Œã€‚
    """
    log = structlog.get_logger("test_core_flow")
    log.info("--- å¼€å§‹æ ¸å¿ƒæµç¨‹æµ‹è¯• (ä½¿ç”¨ DebugEngine) ---")

    DB_FILE = "transhub_core_test.db"
    if os.path.exists(DB_FILE): os.remove(DB_FILE)
    apply_migrations(DB_FILE)
    
    handler = DefaultPersistenceHandler(db_path=DB_FILE)
    
    debug_config = DebugEngineConfig(fail_on_text="cherry", fail_is_retryable=True)
    debug_engine = DebugEngine(config=debug_config)
    rate_limiter = RateLimiter(refill_rate=2, capacity=1)
    
    coordinator = Coordinator(
        persistence_handler=handler,
        engines={"debug": debug_engine},
        active_engine_name="debug",
        rate_limiter=rate_limiter
    )

    try:
        coordinator.request(target_langs=['jp'], text_content="apple")
        coordinator.request(target_langs=['jp'], text_content="banana")
        coordinator.request(target_langs=['jp'], text_content="cherry")

        start_time = time.monotonic()
        results = list(coordinator.process_pending_translations(
            target_lang="jp", batch_size=1, max_retries=1, initial_backoff=0.1
        ))
        duration = time.monotonic() - start_time
        
        log.info("æ ¸å¿ƒæµç¨‹æµ‹è¯•å®Œæˆ", duration=f"{duration:.2f}s")
        assert len(results) == 3
        assert duration > 1.0, "é€Ÿç‡é™åˆ¶å™¨æœªç”Ÿæ•ˆ"
        
        cherry_result = next(r for r in results if r.original_content == "cherry")
        assert cherry_result.status == TranslationStatus.FAILED, "é‡è¯•é€»è¾‘æœªç”Ÿæ•ˆ"

        log.info("âœ… æ ¸å¿ƒæµç¨‹æµ‹è¯•æˆåŠŸï¼")

    finally:
        coordinator.close()


def test_garbage_collection():
    """ç‹¬ç«‹çš„åƒåœ¾å›æ”¶åŠŸèƒ½æµ‹è¯•ã€‚"""
    log = structlog.get_logger("test_gc")
    log.info("--- å¼€å§‹åƒåœ¾å›æ”¶ (GC) æµ‹è¯• ---")

    DB_FILE = "transhub_gc_test.db"
    if os.path.exists(DB_FILE): os.remove(DB_FILE)
    apply_migrations(DB_FILE)
    
    handler = DefaultPersistenceHandler(db_path=DB_FILE)
    coordinator = Coordinator(
        persistence_handler=handler,
        engines={"debug": DebugEngine(DebugEngineConfig())},
        active_engine_name="debug"
    )

    try:
        with handler.transaction() as cursor:
            cursor.execute("INSERT INTO th_content (id, value, created_at) VALUES (1, 'old_content', '2020-01-01 10:00:00')")
            cursor.execute("INSERT INTO th_content (id, value) VALUES (2, 'active_content')")
            cursor.execute("INSERT INTO th_content (id, value, created_at) VALUES (3, 'orphan_content', '2020-01-01 11:00:00')")
            cursor.execute("INSERT INTO th_sources (business_id, content_id, last_seen_at) VALUES ('source:old', 1, '2020-01-01 10:00:00')")
            cursor.execute("INSERT INTO th_sources (business_id, content_id, last_seen_at) VALUES ('source:active', 2, ?)", (time.strftime('%Y-%m-%d %H:%M:%S'),))

        stats_dry = coordinator.run_garbage_collection(retention_days=1000, dry_run=True)
        assert stats_dry["deleted_sources"] == 1 and stats_dry["deleted_content"] == 1
        
        stats_real = coordinator.run_garbage_collection(retention_days=1000, dry_run=False)
        assert stats_real["deleted_sources"] == 1 and stats_real["deleted_content"] == 2

        with handler.transaction() as cursor:
            cursor.execute("SELECT COUNT(*) FROM th_content")
            assert cursor.fetchone()[0] == 1
        
        log.info("âœ… åƒåœ¾å›æ”¶ (GC) æµ‹è¯•æˆåŠŸï¼")

    finally:
        coordinator.close()


def test_openai_engine_flow():
    """
    æµ‹è¯• OpenAIEngineï¼Œå¹¶èƒ½æ™ºèƒ½å¤„ç†å› é…ç½®é—®é¢˜ï¼ˆå¦‚æ— æ•ˆKeyï¼‰å¯¼è‡´çš„å¤±è´¥ã€‚
    """
    log = structlog.get_logger("test_openai_engine")
    
    try:
        openai_config = OpenAIEngineConfig()
        if not openai_config.base_url:
            log.warning("æœªæ‰¾åˆ° TH_OPENAI_ENDPOINT é…ç½®ï¼Œè·³è¿‡ OpenAI å¼•æ“æµ‹è¯•ã€‚")
            return
    except Exception as e:
        log.warning(f"åŠ è½½ OpenAI é…ç½®æ—¶å‡ºé”™ï¼Œè·³è¿‡æµ‹è¯•: {e}")
        return

    log.info("--- å¼€å§‹ OpenAI å¼•æ“æµç¨‹æµ‹è¯• ---", model=openai_config.model, base_url=openai_config.base_url)
    
    DB_FILE = "transhub_openai_test.db"
    if os.path.exists(DB_FILE): os.remove(DB_FILE)
    apply_migrations(DB_FILE)
    
    handler = DefaultPersistenceHandler(db_path=DB_FILE)
    openai_engine = OpenAIEngine(config=openai_config)
    
    coordinator = Coordinator(
        persistence_handler=handler,
        engines={"openai": openai_engine},
        active_engine_name="openai"
    )

    try:
        text_to_translate = "Hello, world! This is a test of the Trans-Hub system."
        target_lang = "Spanish"
        coordinator.request(target_langs=[target_lang], text_content=text_to_translate)
        results = list(coordinator.process_pending_translations(target_lang=target_lang))
        
        assert len(results) == 1, "åº”è¯¥åªè¿”å›ä¸€ä¸ªç»“æœ"
        result = results[0]
        
        log.info("ç¿»è¯‘ç»“æœ", result=result)
        
        if result.status == TranslationStatus.TRANSLATED:
            assert "Hola, mundo" in result.translated_content, f"ç¿»è¯‘ç»“æœä¸ç¬¦åˆé¢„æœŸ: {result.translated_content}"
            log.info("âœ… OpenAI å¼•æ“æµ‹è¯•æˆåŠŸï¼(API Key æœ‰æ•ˆ)")
        elif result.status == TranslationStatus.FAILED:
            assert result.error is not None, "å¤±è´¥ç»“æœå¿…é¡»åŒ…å«é”™è¯¯ä¿¡æ¯"
            if "401" in result.error:
                log.warning("âœ… æµ‹è¯•æ”¶åˆ° 401 é”™è¯¯ï¼Œå¼•æ“é”™è¯¯å¤„ç†é€»è¾‘å·¥ä½œæ­£å¸¸ã€‚")
            else:
                assert False, f"å‘ç”Ÿé 401 çš„æ„å¤–é”™è¯¯: {result.error}"
        else:
             assert False, f"ç¿»è¯‘ç»“æœçŠ¶æ€å¼‚å¸¸: {result.status}"
    finally:
        coordinator.close()


def main():
    """ä¸»å‡½æ•°ï¼Œç»Ÿä¸€æ‰§è¡Œæ‰€æœ‰æµ‹è¯•ã€‚"""
    # 1. åœ¨ç¨‹åºæœ€å¼€å§‹ä¸»åŠ¨åŠ è½½ .env æ–‡ä»¶
    if load_dotenv():
        print("âœ… .env æ–‡ä»¶å·²åŠ è½½ã€‚")
    else:
        print("âš ï¸ æœªæ‰¾åˆ° .env æ–‡ä»¶ï¼Œå°†ä¾èµ–ç³»ç»Ÿç¯å¢ƒå˜é‡ã€‚")

    # 2. é…ç½®æ—¥å¿—ç³»ç»Ÿ
    setup_logging(log_level="INFO", log_format="console")
    
    # 3. ç»‘å®šå”¯ä¸€çš„è°ƒç”¨é“¾ ID
    correlation_id = str(uuid.uuid4())
    structlog.contextvars.bind_contextvars(correlation_id=correlation_id)
    
    root_log = structlog.get_logger("main_test_runner")
    root_log.info("======== Trans-Hub v1.0 æœ€ç»ˆåŠŸèƒ½éªŒè¯å¼€å§‹ ========")
    
    try:
        # 4. æŒ‰é¡ºåºè¿è¡Œæ‰€æœ‰æµ‹è¯•å¥—ä»¶
        test_core_flow_with_debug_engine()
        test_garbage_collection()
        test_openai_engine_flow()
        
        root_log.info("ğŸ‰ ======== æ‰€æœ‰æµ‹è¯•æˆåŠŸé€šè¿‡ï¼Trans-Hub v1.0 æ ¸å¿ƒåŠŸèƒ½å®Œæˆï¼ ======== ğŸ‰")
        
    except Exception:
        root_log.error("âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿæœªæ•è·çš„å¼‚å¸¸ï¼", exc_info=True)
        # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œä»¥ä¾¿ CI/CD ç¯å¢ƒèƒ½æ•è·åˆ°éé›¶é€€å‡ºç 
        raise
    finally:
        # 5. æ¸…ç†ä¸Šä¸‹æ–‡å˜é‡
        structlog.contextvars.clear_contextvars()


if __name__ == "__main__":
    main()